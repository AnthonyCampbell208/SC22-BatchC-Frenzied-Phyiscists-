{"backend_state":"init","connection_file":"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/.local/share/jupyter/runtime/kernel-08ff4176-eda1-4c2e-89d8-0109617f6564.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"1f6bde","input":"#predicting results\ny_hat = my_SVC_model.predict(x_test)","pos":37,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"26cd3d","input":"#Confusion Matrix\n#sns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\n#acc = accuracy_score(y_test, y_hat)\n#fone_score = f1_score(y_test, y_hat)\n#rec = recall_score(y_test, y_hat)\n#prec = precision_score(y_test, y_hat)\n\n#accuracy, f1 score, recall, precision\n#print(\"Accuracy: \" , acc , \"f1 Score: \" , fone_score, \"Recall: \" , rec, \"Precision: \" , prec)","pos":41,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"2869ad","input":"#from sklearn.model_selection import GridSearchCV\n#from sklearn.svm import SVC as svc\n#from sklearn import preprocessing\n#from scipy import stats\n\n#mdl = svc()\n#param_grid = {\"C\": [.1, 1, 10, 100, 1000], 'gamma': [.1, 1, 10, 100, 1000], 'kernel': ['poly', 'linear', 'rbf', 'sigmoid']}\n#grid = GridSearchCV(mdl, param_grid, refit = True, verbose = 7)\n#grid.fit(x_train, y_train)\n\n\n#grid_search = GridSearchCV(mdl, param_grid = grid_list, cv = 5)\n#grid_search.fit(x_train, y_train)\n#print(grid.best_params_)\n#print(\"hi\")","pos":49,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4bb01a","input":"heart_dfs = heart_df.copy()\ntarget = heart_dfs[\"HeartDisease\"]\ninput_columns = heart_dfs.loc[:, heart_dfs.columns != \"HeartDisease\"]\ny = heart_df[\"HeartDisease\"]\nparam_grid = {'n_neighbors': range(1, 400)}\n\nx = KNN()\ngrid_x = GridSearchCV(x, param_grid)\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2,stratify =y, random_state=42)\n\ngrid_x.fit(x_train, y_train)\nprint(grid_x.best_params_)","pos":16,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"5679c3","input":"y_pred_proba = classifier.predict_proba(x_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"heart dataframe, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n\"\"\"fpr = dict()\ntpr = dict()\nroc_auc = dict()\n\ny = label_binarize(y, classes=[0, 1, 2,])\nn_classes = y.shape[1]\n\n\nfor i in y_test:\n    i = int(i)\ny_test = list(y_test)\nfor i in y_pred:\n    i = int(i)\ny_pred = list(y_pred)\nprint(type(y_test))\nfor i in y_pred:\n    for x in y_test:\n        if i == -1 <= x:\n            print(i)\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[0:i], y_pred[0:i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\nplt.figure()\nlw = 2\nplt.plot(\n    fpr[2],\n    tpr[2],\n    color=\"darkorange\",\n    lw=lw,\n    label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n)\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver operating characteristic example\")\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n#This plots the tradeoff of positive rate to false positive rate(roc curve)\"\"\"\n\"\"\"fitted_y = np.array(y_pred)\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(heart_df.loc[:, heart_df.columns != \"HeartDisease\"],heart_df['HeartDisease'],c='red', marker='o', alpha=0.5)\nax.plot_surface(x_test,y_test,y_pred.reshape(x_test.shape), color='b', alpha=0.3)\nax.set_xlabel('Price')\nax.set_ylabel('AdSpends')\nax.set_zlabel('Sales')\nplt.show()\"\"\"","pos":29,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"605396","input":"\"\"\"#y_hat = KNN_model.predict(x_test)\nmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#00AAFF'])\ncmap_bold = ListedColormap(['#FF0000', '#00FF00', '#00AAFF'])\n\nclf = neighbors.KNeighborsClassifier(n_neighbors = 23, weights='distance')\nclf.fit(x_train, y_train)\n\nx_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\ny_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\"\"\"","pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6c1a32","input":"(89)/(89+12)\n(65)/(65+18)","pos":33,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"7a3683","input":"heart_dfs = heart_df.copy()\ntarget = heart_dfs[\"HeartDisease\"]\ninput_columns = heart_dfs.loc[:, heart_dfs.columns != \"HeartDisease\"]\n#sc = StandardScaler()\n#x_train = sc.fit_transform(x_train)\n#x_test = sc.transform(x_test)\n\n\n\n\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2,stratify =target, random_state=42)\nKNN_OLD_MODEL = KNN()\nKNN_model = KNN(n_neighbors = 23)\nKNN_model.fit(x_train,y_train)\n\ny_hat = KNN_model.predict(x_test)\n\ntotal_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)\n\n\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_hat)\nprec = precision_score(y_test, y_hat)\nrecall = recall_score(y_test, y_hat)\nf1 = f1_score(y_test, y_hat)\nscores['KNN_ADJUSTED'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['KNN_ADJUSTED'])","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9f2cce","input":"# define x as all columns but heart disease\n\nX = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\nX = (X - np.min(X)) / (np.max(X) - np.min(X))\n#define y as heart_disease\ny = heart_df['HeartDisease']\n#split data set 80 percent train: 20 percent test\n\n\nn_iter = 1000\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n#scales down x_values\nst_x= StandardScaler()\nx_train= st_x.fit_transform(X_train)\nx_test= st_x.transform(X_test)\nthresholder = VarianceThreshold(threshold=.5)\n\nx_train = thresholder.fit_transform(x_train)\nx_test = thresholder.fit_transform(x_test)\n#create object model\ngnb = GaussianNB(priors=None, var_smoothing=1e-06)\n#fit object model\ngnb.fit(x_train, y_train)\nGaussianNB(priors=None, var_smoothing= 1)\ny_pred = gnb.predict(x_test)\n#print(\"Naive Bayes score: \",gnb.score(X_test, y_test))#\n#print(\"Number of mislabeled points out of a total %d points : %d\"\n\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\nscores['NAIVEBAYES'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['NAIVEBAYES'])\nprint(\"Naive Bayes score: \",gnb.score(x_test, y_test))\n","pos":31,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a2715d","input":"np.array(y_test)","pos":39,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ae328d","input":"","pos":0,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b8439d","input":"","pos":7,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"be3779","input":"y_hat","pos":38,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"c1e1c5","input":"","pos":34,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"c6494e","input":"x_test.shape","pos":12,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"d8b80d","input":"# Please save scores like the example below\nscores['knn'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}","pos":22,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ded656","input":"#print(y_hat)\nprint(np.array(y_test))\n\n\"\"\"total_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)\"\"\"\n\"\"\"sns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_hat)\nprec = precision_score(y_test, y_hat, average='micro')\nrecall = recall_score(y_test, y_hat, average='micro')\nf1 = f1_score(y_test, y_hat, average='micro')\nscores['KNN'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['KNN'])\"\"\"","pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"e7eb4b","input":"mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(1000, 35), alpha=0.05, max_iter=200, random_state = 1, activation='relu', learning_rate='adaptive')\nmlp.fit(x_train, y_train)\ny_hat = mlp.predict(x_test)\nprint(y_hat)\nprint(np.array(y_test))\ntotal_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_hat)\nprec = precision_score(y_test, y_hat, average='micro')\nrecall = recall_score(y_test, y_hat, average='micro')\nf1 = f1_score(y_test, y_hat, average='micro')\nscores['mlp'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['mlp'])","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"e8d731","input":"#MSE\n#total_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\n#mean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \n#print(mean_squared_error)","pos":40,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"eb41fc","input":"heart_dfs = heart_df.copy()\ntarget = heart_dfs[\"HeartDisease\"]\ninput_columns = heart_dfs.loc[:, heart_dfs.columns != \"HeartDisease\"]\ny = heart_df[\"HeartDisease\"]\nparam_grid = {'var_smoothing':range(0,200)}\nx = GaussianNB()\ngrid_x = GridSearchCV(x, param_grid)\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2,stratify =y, random_state=42)\n\ngrid_x.fit(x_train, y_train)\nprint(grid_x.best_params_)","pos":30,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ee5f57","input":"","pos":51,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ef2113","input":"#ADABOOST\n# parameters = {'n_estimators':[50, 100, 125, 150], 'learning_rate': [0.01, 0.1, 0.3, 0.5]}\n# scoring = ['precision', 'accuracy', 'recall', 'f1']\n\n\n# for score in scoring:\n#     abc = AdaBoostClassifier()\n#     grid_abc = GridSearchCV(abc, parameters, scoring=score)\n#     grid_abc.fit(x_train, y_train)\n\n\n#     print(\"best params for %s: \" % score)\n#     print(grid_abc.best_params_)\n\n#     means = grid_abc.cv_results_[\"mean_test_score\"]\n\n#     print(\"mean scores\")\n#     for mean, params in zip(means, grid_abc.cv_results_[\"params\"]):\n#         print(\"%0.5f for %r\" % (mean, params))\n\nabc = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\nabc.fit(x_train, y_train)\n\ny_predictions = abc.predict(x_test)\n\ntotal_squared_error = (np.sum((y_test - y_predictions)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \n#print(mean_squared_error)\nsns.heatmap(confusion_matrix(y_test, y_predictions), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_predictions)\nprec = precision_score(y_test, y_predictions, average='micro')\nrecall = recall_score(y_test, y_predictions, average='micro')\nf1 = f1_score(y_test, y_predictions, average='micro')\nscores['Adaboost'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['Adaboost'])\n\n","pos":14,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f42af9","input":"","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"00f5ec","input":"target = heart_df[\"HeartDisease\"]\ninput_columns = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.3)\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","pos":10,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"f72a8a","input":"#x is everything but heart disease\nx = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\n#y is heart disease\ny = heart_df['HeartDisease']\n# splits dataset; 80 percent train: 20 percent test\nx_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)\n#scales down the x values\nst_x= StandardScaler()\nx_train= st_x.fit_transform(x_train)\nx_test= st_x.transform(x_test)\nlr_clf = LogisticRegression(random_state=42)\n#Fits dataset\nlr_clf.fit(x_train, y_train)\n#gets predicted values\ny_pred= lr_clf.predict(x_test)\n#compares predictions to actual values\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n\n\"\"\"total_squared_error = (np.sum((y_test - y_pred)**2))\nmean_squared_error = total_squared_error/len(y_test)\nprint(mean_squared_error)\"\"\"\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\nscores['LOGISTICREGRESSION'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['LOGISTICREGRESSION'])\n\n","output":{"0":{"name":"stdout","output_type":"stream","text":"{'accuracy': 0.8478260869565217, 'precision': 0.8495575221238938, 'recall': 0.897196261682243, 'f1_score': 0.8727272727272727}\n"},"1":{"data":{"image/png":"0dc2221b6f39dd0fd704be0c36c39e9b414dee61","text/plain":"<Figure size 432x288 with 3 Axes>"},"exec_count":14,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":24,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"5e1f5c","input":"#Confusion Matrix\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_hat)\nfone_score = f1_score(y_test, y_hat)\nrec = recall_score(y_test, y_hat)\nprec = precision_score(y_test, y_hat)\n\n#accuracy, f1 score, recall, precision\nprint(\"Accuracy: \" , acc , \"f1 Score: \" , fone_score, \"Recall: \" , rec, \"Precision: \" , prec)","output":{"0":{"ename":"NameError","evalue":"name 'y_hat' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Confusion Matrix\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(confusion_matrix(y_test, \u001b[43my_hat\u001b[49m), annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_hat)\n\u001b[1;32m      4\u001b[0m fone_score \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_hat)\n","\u001b[0;31mNameError\u001b[0m: name 'y_hat' is not defined"]}},"pos":48,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"1dc695","input":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.svm import SVC as svc\nfrom sklearn import preprocessing\nfrom scipy import stats\n\n# target = heart_df['HeartDisease']\n# input_columns = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\n\n# # splitting the data\n# x_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2, random_state = 45)\n\nmdl = svc()\n# 'kernel': ('poly', 'linear', 'rbf', 'sigmoid')\n\nrand_list = {'C': list(range(1, 100)), 'gamma': list(range(1, 100)), 'kernel': ['poly', 'linear', 'rbf', 'sigmoid']}\nrand_search = RandomizedSearchCV(mdl, rand_list, n_iter = 100, cv = 5, verbose=100)\nrand_search.fit(x_train, y_train)\nrand_search.best_params_","output":{"0":{"name":"stdout","output_type":"stream","text":"Fitting 5 folds for each of 100 candidates, totalling 500 fits\n[CV 1/5; 1/100] START C=13, gamma=89, kernel=linear.............................\n[CV 1/5; 1/100] END C=13, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 1/100] START C=13, gamma=89, kernel=linear.............................\n[CV 2/5; 1/100] END C=13, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 1/100] START C=13, gamma=89, kernel=linear.............................\n[CV 3/5; 1/100] END C=13, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 1/100] START C=13, gamma=89, kernel=linear.............................\n[CV 4/5; 1/100] END C=13, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 1/100] START C=13, gamma=89, kernel=linear.............................\n[CV 5/5; 1/100] END C=13, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 2/100] START C=19, gamma=95, kernel=rbf................................\n[CV 1/5; 2/100] END ...C=19, gamma=95, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 2/100] START C=19, gamma=95, kernel=rbf................................\n[CV 2/5; 2/100] END ...C=19, gamma=95, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 2/100] START C=19, gamma=95, kernel=rbf................................\n[CV 3/5; 2/100] END ...C=19, gamma=95, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 2/100] START C=19, gamma=95, kernel=rbf................................\n[CV 4/5; 2/100] END ...C=19, gamma=95, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 2/100] START C=19, gamma=95, kernel=rbf................................\n[CV 5/5; 2/100] END ...C=19, gamma=95, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 3/100] START C=83, gamma=59, kernel=sigmoid............................\n[CV 1/5; 3/100] END C=83, gamma=59, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 3/100] START C=83, gamma=59, kernel=sigmoid............................\n[CV 2/5; 3/100] END C=83, gamma=59, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 3/100] START C=83, gamma=59, kernel=sigmoid............................\n[CV 3/5; 3/100] END C=83, gamma=59, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 3/100] START C=83, gamma=59, kernel=sigmoid............................\n[CV 4/5; 3/100] END C=83, gamma=59, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 3/100] START C=83, gamma=59, kernel=sigmoid............................\n[CV 5/5; 3/100] END C=83, gamma=59, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 4/100] START C=72, gamma=75, kernel=linear.............................\n[CV 1/5; 4/100] END C=72, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 4/100] START C=72, gamma=75, kernel=linear.............................\n[CV 2/5; 4/100] END C=72, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 4/100] START C=72, gamma=75, kernel=linear.............................\n[CV 3/5; 4/100] END C=72, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 4/100] START C=72, gamma=75, kernel=linear.............................\n[CV 4/5; 4/100] END C=72, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 4/100] START C=72, gamma=75, kernel=linear.............................\n[CV 5/5; 4/100] END C=72, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 5/100] START C=89, gamma=87, kernel=sigmoid............................\n[CV 1/5; 5/100] END C=89, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 5/100] START C=89, gamma=87, kernel=sigmoid............................\n[CV 2/5; 5/100] END C=89, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 5/100] START C=89, gamma=87, kernel=sigmoid............................\n[CV 3/5; 5/100] END C=89, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 5/100] START C=89, gamma=87, kernel=sigmoid............................\n[CV 4/5; 5/100] END C=89, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 5/100] START C=89, gamma=87, kernel=sigmoid............................\n[CV 5/5; 5/100] END C=89, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 6/100] START C=66, gamma=22, kernel=sigmoid............................\n[CV 1/5; 6/100] END C=66, gamma=22, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 6/100] START C=66, gamma=22, kernel=sigmoid............................\n[CV 2/5; 6/100] END C=66, gamma=22, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 6/100] START C=66, gamma=22, kernel=sigmoid............................\n[CV 3/5; 6/100] END C=66, gamma=22, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 6/100] START C=66, gamma=22, kernel=sigmoid............................\n[CV 4/5; 6/100] END C=66, gamma=22, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 6/100] START C=66, gamma=22, kernel=sigmoid............................\n[CV 5/5; 6/100] END C=66, gamma=22, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 7/100] START C=94, gamma=72, kernel=poly...............................\n[CV 1/5; 7/100] END ..C=94, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 7/100] START C=94, gamma=72, kernel=poly...............................\n[CV 2/5; 7/100] END ..C=94, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 7/100] START C=94, gamma=72, kernel=poly...............................\n[CV 3/5; 7/100] END ..C=94, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 7/100] START C=94, gamma=72, kernel=poly...............................\n[CV 4/5; 7/100] END ..C=94, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 7/100] START C=94, gamma=72, kernel=poly...............................\n[CV 5/5; 7/100] END ..C=94, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 8/100] START C=18, gamma=33, kernel=linear.............................\n[CV 1/5; 8/100] END C=18, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 8/100] START C=18, gamma=33, kernel=linear.............................\n[CV 2/5; 8/100] END C=18, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 8/100] START C=18, gamma=33, kernel=linear.............................\n[CV 3/5; 8/100] END C=18, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 8/100] START C=18, gamma=33, kernel=linear.............................\n[CV 4/5; 8/100] END C=18, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 8/100] START C=18, gamma=33, kernel=linear.............................\n[CV 5/5; 8/100] END C=18, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 9/100] START C=12, gamma=6, kernel=linear..............................\n[CV 1/5; 9/100] END .C=12, gamma=6, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 9/100] START C=12, gamma=6, kernel=linear..............................\n[CV 2/5; 9/100] END .C=12, gamma=6, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 9/100] START C=12, gamma=6, kernel=linear..............................\n[CV 3/5; 9/100] END .C=12, gamma=6, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 9/100] START C=12, gamma=6, kernel=linear..............................\n[CV 4/5; 9/100] END .C=12, gamma=6, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 9/100] START C=12, gamma=6, kernel=linear..............................\n[CV 5/5; 9/100] END .C=12, gamma=6, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 10/100] START C=35, gamma=21, kernel=linear............................\n[CV 1/5; 10/100] END C=35, gamma=21, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 10/100] START C=35, gamma=21, kernel=linear............................\n[CV 2/5; 10/100] END C=35, gamma=21, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 10/100] START C=35, gamma=21, kernel=linear............................\n[CV 3/5; 10/100] END C=35, gamma=21, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 10/100] START C=35, gamma=21, kernel=linear............................\n[CV 4/5; 10/100] END C=35, gamma=21, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 10/100] START C=35, gamma=21, kernel=linear............................\n[CV 5/5; 10/100] END C=35, gamma=21, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 11/100] START C=94, gamma=35, kernel=poly..............................\n[CV 1/5; 11/100] END .C=94, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 11/100] START C=94, gamma=35, kernel=poly..............................\n[CV 2/5; 11/100] END .C=94, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 11/100] START C=94, gamma=35, kernel=poly..............................\n[CV 3/5; 11/100] END .C=94, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 11/100] START C=94, gamma=35, kernel=poly..............................\n[CV 4/5; 11/100] END .C=94, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 11/100] START C=94, gamma=35, kernel=poly..............................\n"},"1":{"name":"stdout","output_type":"stream","text":"[CV 5/5; 11/100] END .C=94, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 12/100] START C=28, gamma=77, kernel=poly..............................\n[CV 1/5; 12/100] END .C=28, gamma=77, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 12/100] START C=28, gamma=77, kernel=poly..............................\n[CV 2/5; 12/100] END .C=28, gamma=77, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 12/100] START C=28, gamma=77, kernel=poly..............................\n[CV 3/5; 12/100] END .C=28, gamma=77, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 12/100] START C=28, gamma=77, kernel=poly..............................\n[CV 4/5; 12/100] END .C=28, gamma=77, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 12/100] START C=28, gamma=77, kernel=poly..............................\n[CV 5/5; 12/100] END .C=28, gamma=77, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 13/100] START C=74, gamma=69, kernel=rbf...............................\n[CV 1/5; 13/100] END ..C=74, gamma=69, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 13/100] START C=74, gamma=69, kernel=rbf...............................\n[CV 2/5; 13/100] END ..C=74, gamma=69, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 13/100] START C=74, gamma=69, kernel=rbf...............................\n[CV 3/5; 13/100] END ..C=74, gamma=69, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 13/100] START C=74, gamma=69, kernel=rbf...............................\n[CV 4/5; 13/100] END ..C=74, gamma=69, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 13/100] START C=74, gamma=69, kernel=rbf...............................\n[CV 5/5; 13/100] END ..C=74, gamma=69, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 14/100] START C=41, gamma=93, kernel=linear............................\n[CV 1/5; 14/100] END C=41, gamma=93, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 14/100] START C=41, gamma=93, kernel=linear............................\n[CV 2/5; 14/100] END C=41, gamma=93, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 14/100] START C=41, gamma=93, kernel=linear............................\n[CV 3/5; 14/100] END C=41, gamma=93, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 14/100] START C=41, gamma=93, kernel=linear............................\n[CV 4/5; 14/100] END C=41, gamma=93, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 14/100] START C=41, gamma=93, kernel=linear............................\n[CV 5/5; 14/100] END C=41, gamma=93, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 15/100] START C=94, gamma=9, kernel=sigmoid............................\n[CV 1/5; 15/100] END C=94, gamma=9, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 15/100] START C=94, gamma=9, kernel=sigmoid............................\n[CV 2/5; 15/100] END C=94, gamma=9, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 15/100] START C=94, gamma=9, kernel=sigmoid............................\n[CV 3/5; 15/100] END C=94, gamma=9, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 15/100] START C=94, gamma=9, kernel=sigmoid............................\n[CV 4/5; 15/100] END C=94, gamma=9, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 15/100] START C=94, gamma=9, kernel=sigmoid............................\n[CV 5/5; 15/100] END C=94, gamma=9, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 16/100] START C=81, gamma=24, kernel=linear............................\n[CV 1/5; 16/100] END C=81, gamma=24, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 16/100] START C=81, gamma=24, kernel=linear............................\n[CV 2/5; 16/100] END C=81, gamma=24, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 16/100] START C=81, gamma=24, kernel=linear............................\n[CV 3/5; 16/100] END C=81, gamma=24, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 16/100] START C=81, gamma=24, kernel=linear............................\n[CV 4/5; 16/100] END C=81, gamma=24, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 16/100] START C=81, gamma=24, kernel=linear............................\n[CV 5/5; 16/100] END C=81, gamma=24, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 17/100] START C=49, gamma=51, kernel=poly..............................\n[CV 1/5; 17/100] END .C=49, gamma=51, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 17/100] START C=49, gamma=51, kernel=poly..............................\n[CV 2/5; 17/100] END .C=49, gamma=51, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 17/100] START C=49, gamma=51, kernel=poly..............................\n[CV 3/5; 17/100] END .C=49, gamma=51, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 17/100] START C=49, gamma=51, kernel=poly..............................\n[CV 4/5; 17/100] END .C=49, gamma=51, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 17/100] START C=49, gamma=51, kernel=poly..............................\n[CV 5/5; 17/100] END .C=49, gamma=51, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 18/100] START C=70, gamma=28, kernel=linear............................\n[CV 1/5; 18/100] END C=70, gamma=28, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 18/100] START C=70, gamma=28, kernel=linear............................\n[CV 2/5; 18/100] END C=70, gamma=28, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 18/100] START C=70, gamma=28, kernel=linear............................\n[CV 3/5; 18/100] END C=70, gamma=28, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 18/100] START C=70, gamma=28, kernel=linear............................\n[CV 4/5; 18/100] END C=70, gamma=28, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 18/100] START C=70, gamma=28, kernel=linear............................\n[CV 5/5; 18/100] END C=70, gamma=28, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 19/100] START C=72, gamma=41, kernel=sigmoid...........................\n[CV 1/5; 19/100] END C=72, gamma=41, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 19/100] START C=72, gamma=41, kernel=sigmoid...........................\n[CV 2/5; 19/100] END C=72, gamma=41, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 19/100] START C=72, gamma=41, kernel=sigmoid...........................\n[CV 3/5; 19/100] END C=72, gamma=41, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 19/100] START C=72, gamma=41, kernel=sigmoid...........................\n[CV 4/5; 19/100] END C=72, gamma=41, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 19/100] START C=72, gamma=41, kernel=sigmoid...........................\n[CV 5/5; 19/100] END C=72, gamma=41, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 20/100] START C=29, gamma=55, kernel=poly..............................\n[CV 1/5; 20/100] END .C=29, gamma=55, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 20/100] START C=29, gamma=55, kernel=poly..............................\n[CV 2/5; 20/100] END .C=29, gamma=55, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 20/100] START C=29, gamma=55, kernel=poly..............................\n[CV 3/5; 20/100] END .C=29, gamma=55, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 20/100] START C=29, gamma=55, kernel=poly..............................\n[CV 4/5; 20/100] END .C=29, gamma=55, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 20/100] START C=29, gamma=55, kernel=poly..............................\n[CV 5/5; 20/100] END .C=29, gamma=55, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 21/100] START C=75, gamma=83, kernel=rbf...............................\n[CV 1/5; 21/100] END ..C=75, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 21/100] START C=75, gamma=83, kernel=rbf...............................\n[CV 2/5; 21/100] END ..C=75, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 21/100] START C=75, gamma=83, kernel=rbf...............................\n[CV 3/5; 21/100] END ..C=75, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 21/100] START C=75, gamma=83, kernel=rbf...............................\n[CV 4/5; 21/100] END ..C=75, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 21/100] START C=75, gamma=83, kernel=rbf...............................\n[CV 5/5; 21/100] END ..C=75, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 22/100] START C=42, gamma=57, kernel=rbf...............................\n[CV 1/5; 22/100] END ..C=42, gamma=57, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 22/100] START C=42, gamma=57, kernel=rbf...............................\n[CV 2/5; 22/100] END ..C=42, gamma=57, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 22/100] START C=42, gamma=57, kernel=rbf...............................\n[CV 3/5; 22/100] END ..C=42, gamma=57, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 22/100] START C=42, gamma=57, kernel=rbf...............................\n[CV 4/5; 22/100] END ..C=42, gamma=57, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 22/100] START C=42, gamma=57, kernel=rbf...............................\n[CV 5/5; 22/100] END ..C=42, gamma=57, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 23/100] START C=77, gamma=32, kernel=rbf...............................\n[CV 1/5; 23/100] END ..C=77, gamma=32, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 23/100] START C=77, gamma=32, kernel=rbf...............................\n[CV 2/5; 23/100] END ..C=77, gamma=32, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 23/100] START C=77, gamma=32, kernel=rbf...............................\n[CV 3/5; 23/100] END ..C=77, gamma=32, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 23/100] START C=77, gamma=32, kernel=rbf...............................\n[CV 4/5; 23/100] END ..C=77, gamma=32, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 23/100] START C=77, gamma=32, kernel=rbf...............................\n[CV 5/5; 23/100] END ..C=77, gamma=32, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 24/100] START C=84, gamma=9, kernel=linear.............................\n[CV 1/5; 24/100] END C=84, gamma=9, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 24/100] START C=84, gamma=9, kernel=linear.............................\n[CV 2/5; 24/100] END C=84, gamma=9, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 24/100] START C=84, gamma=9, kernel=linear.............................\n"},"2":{"name":"stdout","output_type":"stream","text":"[CV 3/5; 24/100] END C=84, gamma=9, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 24/100] START C=84, gamma=9, kernel=linear.............................\n[CV 4/5; 24/100] END C=84, gamma=9, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 24/100] START C=84, gamma=9, kernel=linear.............................\n[CV 5/5; 24/100] END C=84, gamma=9, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 25/100] START C=21, gamma=17, kernel=sigmoid...........................\n[CV 1/5; 25/100] END C=21, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 25/100] START C=21, gamma=17, kernel=sigmoid...........................\n[CV 2/5; 25/100] END C=21, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 25/100] START C=21, gamma=17, kernel=sigmoid...........................\n[CV 3/5; 25/100] END C=21, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 25/100] START C=21, gamma=17, kernel=sigmoid...........................\n[CV 4/5; 25/100] END C=21, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 25/100] START C=21, gamma=17, kernel=sigmoid...........................\n[CV 5/5; 25/100] END C=21, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 26/100] START C=81, gamma=3, kernel=sigmoid............................\n[CV 1/5; 26/100] END C=81, gamma=3, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 26/100] START C=81, gamma=3, kernel=sigmoid............................\n[CV 2/5; 26/100] END C=81, gamma=3, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 26/100] START C=81, gamma=3, kernel=sigmoid............................\n[CV 3/5; 26/100] END C=81, gamma=3, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 26/100] START C=81, gamma=3, kernel=sigmoid............................\n[CV 4/5; 26/100] END C=81, gamma=3, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 26/100] START C=81, gamma=3, kernel=sigmoid............................\n[CV 5/5; 26/100] END C=81, gamma=3, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 27/100] START C=25, gamma=97, kernel=linear............................\n[CV 1/5; 27/100] END C=25, gamma=97, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 27/100] START C=25, gamma=97, kernel=linear............................\n[CV 2/5; 27/100] END C=25, gamma=97, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 27/100] START C=25, gamma=97, kernel=linear............................\n[CV 3/5; 27/100] END C=25, gamma=97, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 27/100] START C=25, gamma=97, kernel=linear............................\n[CV 4/5; 27/100] END C=25, gamma=97, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 27/100] START C=25, gamma=97, kernel=linear............................\n[CV 5/5; 27/100] END C=25, gamma=97, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 28/100] START C=33, gamma=36, kernel=linear............................\n[CV 1/5; 28/100] END C=33, gamma=36, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 28/100] START C=33, gamma=36, kernel=linear............................\n[CV 2/5; 28/100] END C=33, gamma=36, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 28/100] START C=33, gamma=36, kernel=linear............................\n[CV 3/5; 28/100] END C=33, gamma=36, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 28/100] START C=33, gamma=36, kernel=linear............................\n[CV 4/5; 28/100] END C=33, gamma=36, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 28/100] START C=33, gamma=36, kernel=linear............................\n[CV 5/5; 28/100] END C=33, gamma=36, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 29/100] START C=38, gamma=8, kernel=poly...............................\n[CV 1/5; 29/100] END ..C=38, gamma=8, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 29/100] START C=38, gamma=8, kernel=poly...............................\n[CV 2/5; 29/100] END ..C=38, gamma=8, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 29/100] START C=38, gamma=8, kernel=poly...............................\n[CV 3/5; 29/100] END ..C=38, gamma=8, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 29/100] START C=38, gamma=8, kernel=poly...............................\n[CV 4/5; 29/100] END ..C=38, gamma=8, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 29/100] START C=38, gamma=8, kernel=poly...............................\n[CV 5/5; 29/100] END ..C=38, gamma=8, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 30/100] START C=77, gamma=94, kernel=poly..............................\n[CV 1/5; 30/100] END .C=77, gamma=94, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 30/100] START C=77, gamma=94, kernel=poly..............................\n[CV 2/5; 30/100] END .C=77, gamma=94, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 30/100] START C=77, gamma=94, kernel=poly..............................\n[CV 3/5; 30/100] END .C=77, gamma=94, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 30/100] START C=77, gamma=94, kernel=poly..............................\n[CV 4/5; 30/100] END .C=77, gamma=94, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 30/100] START C=77, gamma=94, kernel=poly..............................\n[CV 5/5; 30/100] END .C=77, gamma=94, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 31/100] START C=53, gamma=1, kernel=poly...............................\n[CV 1/5; 31/100] END ..C=53, gamma=1, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 31/100] START C=53, gamma=1, kernel=poly...............................\n[CV 2/5; 31/100] END ..C=53, gamma=1, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 31/100] START C=53, gamma=1, kernel=poly...............................\n[CV 3/5; 31/100] END ..C=53, gamma=1, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 31/100] START C=53, gamma=1, kernel=poly...............................\n[CV 4/5; 31/100] END ..C=53, gamma=1, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 31/100] START C=53, gamma=1, kernel=poly...............................\n[CV 5/5; 31/100] END ..C=53, gamma=1, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 32/100] START C=53, gamma=87, kernel=sigmoid...........................\n[CV 1/5; 32/100] END C=53, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 32/100] START C=53, gamma=87, kernel=sigmoid...........................\n[CV 2/5; 32/100] END C=53, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 32/100] START C=53, gamma=87, kernel=sigmoid...........................\n[CV 3/5; 32/100] END C=53, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 32/100] START C=53, gamma=87, kernel=sigmoid...........................\n[CV 4/5; 32/100] END C=53, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 32/100] START C=53, gamma=87, kernel=sigmoid...........................\n[CV 5/5; 32/100] END C=53, gamma=87, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 33/100] START C=56, gamma=23, kernel=rbf...............................\n[CV 1/5; 33/100] END ..C=56, gamma=23, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 33/100] START C=56, gamma=23, kernel=rbf...............................\n[CV 2/5; 33/100] END ..C=56, gamma=23, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 33/100] START C=56, gamma=23, kernel=rbf...............................\n[CV 3/5; 33/100] END ..C=56, gamma=23, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 33/100] START C=56, gamma=23, kernel=rbf...............................\n[CV 4/5; 33/100] END ..C=56, gamma=23, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 33/100] START C=56, gamma=23, kernel=rbf...............................\n[CV 5/5; 33/100] END ..C=56, gamma=23, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 34/100] START C=22, gamma=48, kernel=linear............................\n[CV 1/5; 34/100] END C=22, gamma=48, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 34/100] START C=22, gamma=48, kernel=linear............................\n[CV 2/5; 34/100] END C=22, gamma=48, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 34/100] START C=22, gamma=48, kernel=linear............................\n[CV 3/5; 34/100] END C=22, gamma=48, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 34/100] START C=22, gamma=48, kernel=linear............................\n"},"3":{"name":"stdout","output_type":"stream","text":"[CV 4/5; 34/100] END C=22, gamma=48, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 34/100] START C=22, gamma=48, kernel=linear............................\n[CV 5/5; 34/100] END C=22, gamma=48, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 35/100] START C=49, gamma=70, kernel=sigmoid...........................\n[CV 1/5; 35/100] END C=49, gamma=70, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 35/100] START C=49, gamma=70, kernel=sigmoid...........................\n[CV 2/5; 35/100] END C=49, gamma=70, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 35/100] START C=49, gamma=70, kernel=sigmoid...........................\n[CV 3/5; 35/100] END C=49, gamma=70, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 35/100] START C=49, gamma=70, kernel=sigmoid...........................\n[CV 4/5; 35/100] END C=49, gamma=70, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 35/100] START C=49, gamma=70, kernel=sigmoid...........................\n[CV 5/5; 35/100] END C=49, gamma=70, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 36/100] START C=39, gamma=24, kernel=rbf...............................\n[CV 1/5; 36/100] END ..C=39, gamma=24, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 36/100] START C=39, gamma=24, kernel=rbf...............................\n[CV 2/5; 36/100] END ..C=39, gamma=24, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 36/100] START C=39, gamma=24, kernel=rbf...............................\n[CV 3/5; 36/100] END ..C=39, gamma=24, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 36/100] START C=39, gamma=24, kernel=rbf...............................\n[CV 4/5; 36/100] END ..C=39, gamma=24, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 36/100] START C=39, gamma=24, kernel=rbf...............................\n[CV 5/5; 36/100] END ..C=39, gamma=24, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 37/100] START C=43, gamma=92, kernel=sigmoid...........................\n[CV 1/5; 37/100] END C=43, gamma=92, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 37/100] START C=43, gamma=92, kernel=sigmoid...........................\n[CV 2/5; 37/100] END C=43, gamma=92, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 37/100] START C=43, gamma=92, kernel=sigmoid...........................\n[CV 3/5; 37/100] END C=43, gamma=92, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 37/100] START C=43, gamma=92, kernel=sigmoid...........................\n[CV 4/5; 37/100] END C=43, gamma=92, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 37/100] START C=43, gamma=92, kernel=sigmoid...........................\n[CV 5/5; 37/100] END C=43, gamma=92, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 38/100] START C=66, gamma=35, kernel=rbf...............................\n[CV 1/5; 38/100] END ..C=66, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 38/100] START C=66, gamma=35, kernel=rbf...............................\n[CV 2/5; 38/100] END ..C=66, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 38/100] START C=66, gamma=35, kernel=rbf...............................\n[CV 3/5; 38/100] END ..C=66, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 38/100] START C=66, gamma=35, kernel=rbf...............................\n[CV 4/5; 38/100] END ..C=66, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 38/100] START C=66, gamma=35, kernel=rbf...............................\n[CV 5/5; 38/100] END ..C=66, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 39/100] START C=52, gamma=34, kernel=linear............................\n[CV 1/5; 39/100] END C=52, gamma=34, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 39/100] START C=52, gamma=34, kernel=linear............................\n[CV 2/5; 39/100] END C=52, gamma=34, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 39/100] START C=52, gamma=34, kernel=linear............................\n[CV 3/5; 39/100] END C=52, gamma=34, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 39/100] START C=52, gamma=34, kernel=linear............................\n[CV 4/5; 39/100] END C=52, gamma=34, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 39/100] START C=52, gamma=34, kernel=linear............................\n[CV 5/5; 39/100] END C=52, gamma=34, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 40/100] START C=45, gamma=65, kernel=linear............................\n[CV 1/5; 40/100] END C=45, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 40/100] START C=45, gamma=65, kernel=linear............................\n[CV 2/5; 40/100] END C=45, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 40/100] START C=45, gamma=65, kernel=linear............................\n[CV 3/5; 40/100] END C=45, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 40/100] START C=45, gamma=65, kernel=linear............................\n[CV 4/5; 40/100] END C=45, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 40/100] START C=45, gamma=65, kernel=linear............................\n[CV 5/5; 40/100] END C=45, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 41/100] START C=96, gamma=6, kernel=sigmoid............................\n[CV 1/5; 41/100] END C=96, gamma=6, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 41/100] START C=96, gamma=6, kernel=sigmoid............................\n[CV 2/5; 41/100] END C=96, gamma=6, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 41/100] START C=96, gamma=6, kernel=sigmoid............................\n[CV 3/5; 41/100] END C=96, gamma=6, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 41/100] START C=96, gamma=6, kernel=sigmoid............................\n[CV 4/5; 41/100] END C=96, gamma=6, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 41/100] START C=96, gamma=6, kernel=sigmoid............................\n[CV 5/5; 41/100] END C=96, gamma=6, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 42/100] START C=99, gamma=64, kernel=linear............................\n[CV 1/5; 42/100] END C=99, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 42/100] START C=99, gamma=64, kernel=linear............................\n[CV 2/5; 42/100] END C=99, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 42/100] START C=99, gamma=64, kernel=linear............................\n[CV 3/5; 42/100] END C=99, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 42/100] START C=99, gamma=64, kernel=linear............................\n[CV 4/5; 42/100] END C=99, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 42/100] START C=99, gamma=64, kernel=linear............................\n[CV 5/5; 42/100] END C=99, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 43/100] START C=24, gamma=27, kernel=rbf...............................\n[CV 1/5; 43/100] END ..C=24, gamma=27, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 43/100] START C=24, gamma=27, kernel=rbf...............................\n[CV 2/5; 43/100] END ..C=24, gamma=27, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 43/100] START C=24, gamma=27, kernel=rbf...............................\n[CV 3/5; 43/100] END ..C=24, gamma=27, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 43/100] START C=24, gamma=27, kernel=rbf...............................\n[CV 4/5; 43/100] END ..C=24, gamma=27, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 43/100] START C=24, gamma=27, kernel=rbf...............................\n[CV 5/5; 43/100] END ..C=24, gamma=27, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 44/100] START C=77, gamma=87, kernel=linear............................\n[CV 1/5; 44/100] END C=77, gamma=87, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 44/100] START C=77, gamma=87, kernel=linear............................\n[CV 2/5; 44/100] END C=77, gamma=87, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 44/100] START C=77, gamma=87, kernel=linear............................\n[CV 3/5; 44/100] END C=77, gamma=87, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 44/100] START C=77, gamma=87, kernel=linear............................\n[CV 4/5; 44/100] END C=77, gamma=87, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 44/100] START C=77, gamma=87, kernel=linear............................\n[CV 5/5; 44/100] END C=77, gamma=87, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 45/100] START C=49, gamma=64, kernel=linear............................\n[CV 1/5; 45/100] END C=49, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 45/100] START C=49, gamma=64, kernel=linear............................\n[CV 2/5; 45/100] END C=49, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 45/100] START C=49, gamma=64, kernel=linear............................\n[CV 3/5; 45/100] END C=49, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 45/100] START C=49, gamma=64, kernel=linear............................\n[CV 4/5; 45/100] END C=49, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 45/100] START C=49, gamma=64, kernel=linear............................\n"},"4":{"name":"stdout","output_type":"stream","text":"[CV 5/5; 45/100] END C=49, gamma=64, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 46/100] START C=41, gamma=11, kernel=linear............................\n[CV 1/5; 46/100] END C=41, gamma=11, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 46/100] START C=41, gamma=11, kernel=linear............................\n[CV 2/5; 46/100] END C=41, gamma=11, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 46/100] START C=41, gamma=11, kernel=linear............................\n[CV 3/5; 46/100] END C=41, gamma=11, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 46/100] START C=41, gamma=11, kernel=linear............................\n[CV 4/5; 46/100] END C=41, gamma=11, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 46/100] START C=41, gamma=11, kernel=linear............................\n[CV 5/5; 46/100] END C=41, gamma=11, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 47/100] START C=96, gamma=87, kernel=poly..............................\n[CV 1/5; 47/100] END .C=96, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 47/100] START C=96, gamma=87, kernel=poly..............................\n[CV 2/5; 47/100] END .C=96, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 47/100] START C=96, gamma=87, kernel=poly..............................\n[CV 3/5; 47/100] END .C=96, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 47/100] START C=96, gamma=87, kernel=poly..............................\n[CV 4/5; 47/100] END .C=96, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 47/100] START C=96, gamma=87, kernel=poly..............................\n[CV 5/5; 47/100] END .C=96, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 48/100] START C=81, gamma=38, kernel=linear............................\n[CV 1/5; 48/100] END C=81, gamma=38, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 48/100] START C=81, gamma=38, kernel=linear............................\n[CV 2/5; 48/100] END C=81, gamma=38, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 48/100] START C=81, gamma=38, kernel=linear............................\n[CV 3/5; 48/100] END C=81, gamma=38, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 48/100] START C=81, gamma=38, kernel=linear............................\n[CV 4/5; 48/100] END C=81, gamma=38, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 48/100] START C=81, gamma=38, kernel=linear............................\n[CV 5/5; 48/100] END C=81, gamma=38, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 49/100] START C=46, gamma=44, kernel=rbf...............................\n[CV 1/5; 49/100] END ..C=46, gamma=44, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 49/100] START C=46, gamma=44, kernel=rbf...............................\n[CV 2/5; 49/100] END ..C=46, gamma=44, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 49/100] START C=46, gamma=44, kernel=rbf...............................\n[CV 3/5; 49/100] END ..C=46, gamma=44, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 49/100] START C=46, gamma=44, kernel=rbf...............................\n[CV 4/5; 49/100] END ..C=46, gamma=44, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 49/100] START C=46, gamma=44, kernel=rbf...............................\n[CV 5/5; 49/100] END ..C=46, gamma=44, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 50/100] START C=3, gamma=66, kernel=linear.............................\n[CV 1/5; 50/100] END C=3, gamma=66, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 50/100] START C=3, gamma=66, kernel=linear.............................\n[CV 2/5; 50/100] END C=3, gamma=66, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 50/100] START C=3, gamma=66, kernel=linear.............................\n[CV 3/5; 50/100] END C=3, gamma=66, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 50/100] START C=3, gamma=66, kernel=linear.............................\n[CV 4/5; 50/100] END C=3, gamma=66, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 50/100] START C=3, gamma=66, kernel=linear.............................\n[CV 5/5; 50/100] END C=3, gamma=66, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 51/100] START C=72, gamma=65, kernel=linear............................\n[CV 1/5; 51/100] END C=72, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 51/100] START C=72, gamma=65, kernel=linear............................\n[CV 2/5; 51/100] END C=72, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 51/100] START C=72, gamma=65, kernel=linear............................\n[CV 3/5; 51/100] END C=72, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 51/100] START C=72, gamma=65, kernel=linear............................\n[CV 4/5; 51/100] END C=72, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 51/100] START C=72, gamma=65, kernel=linear............................\n[CV 5/5; 51/100] END C=72, gamma=65, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 52/100] START C=77, gamma=15, kernel=poly..............................\n[CV 1/5; 52/100] END .C=77, gamma=15, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 52/100] START C=77, gamma=15, kernel=poly..............................\n[CV 2/5; 52/100] END .C=77, gamma=15, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 52/100] START C=77, gamma=15, kernel=poly..............................\n[CV 3/5; 52/100] END .C=77, gamma=15, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 52/100] START C=77, gamma=15, kernel=poly..............................\n[CV 4/5; 52/100] END .C=77, gamma=15, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 52/100] START C=77, gamma=15, kernel=poly..............................\n[CV 5/5; 52/100] END .C=77, gamma=15, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 53/100] START C=26, gamma=30, kernel=poly..............................\n[CV 1/5; 53/100] END .C=26, gamma=30, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 53/100] START C=26, gamma=30, kernel=poly..............................\n[CV 2/5; 53/100] END .C=26, gamma=30, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 53/100] START C=26, gamma=30, kernel=poly..............................\n[CV 3/5; 53/100] END .C=26, gamma=30, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 53/100] START C=26, gamma=30, kernel=poly..............................\n[CV 4/5; 53/100] END .C=26, gamma=30, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 53/100] START C=26, gamma=30, kernel=poly..............................\n[CV 5/5; 53/100] END .C=26, gamma=30, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 54/100] START C=23, gamma=17, kernel=sigmoid...........................\n[CV 1/5; 54/100] END C=23, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 54/100] START C=23, gamma=17, kernel=sigmoid...........................\n[CV 2/5; 54/100] END C=23, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 54/100] START C=23, gamma=17, kernel=sigmoid...........................\n[CV 3/5; 54/100] END C=23, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 54/100] START C=23, gamma=17, kernel=sigmoid...........................\n[CV 4/5; 54/100] END C=23, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 54/100] START C=23, gamma=17, kernel=sigmoid...........................\n[CV 5/5; 54/100] END C=23, gamma=17, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 55/100] START C=91, gamma=87, kernel=poly..............................\n[CV 1/5; 55/100] END .C=91, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 55/100] START C=91, gamma=87, kernel=poly..............................\n[CV 2/5; 55/100] END .C=91, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 55/100] START C=91, gamma=87, kernel=poly..............................\n[CV 3/5; 55/100] END .C=91, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 55/100] START C=91, gamma=87, kernel=poly..............................\n[CV 4/5; 55/100] END .C=91, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 55/100] START C=91, gamma=87, kernel=poly..............................\n[CV 5/5; 55/100] END .C=91, gamma=87, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 56/100] START C=87, gamma=33, kernel=linear............................\n[CV 1/5; 56/100] END C=87, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 56/100] START C=87, gamma=33, kernel=linear............................\n[CV 2/5; 56/100] END C=87, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 56/100] START C=87, gamma=33, kernel=linear............................\n[CV 3/5; 56/100] END C=87, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 56/100] START C=87, gamma=33, kernel=linear............................\n[CV 4/5; 56/100] END C=87, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 56/100] START C=87, gamma=33, kernel=linear............................\n[CV 5/5; 56/100] END C=87, gamma=33, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 57/100] START C=23, gamma=8, kernel=sigmoid............................\n[CV 1/5; 57/100] END C=23, gamma=8, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 57/100] START C=23, gamma=8, kernel=sigmoid............................\n[CV 2/5; 57/100] END C=23, gamma=8, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 57/100] START C=23, gamma=8, kernel=sigmoid............................\n[CV 3/5; 57/100] END C=23, gamma=8, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 57/100] START C=23, gamma=8, kernel=sigmoid............................\n[CV 4/5; 57/100] END C=23, gamma=8, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 57/100] START C=23, gamma=8, kernel=sigmoid............................\n[CV 5/5; 57/100] END C=23, gamma=8, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 58/100] START C=9, gamma=83, kernel=rbf................................\n[CV 1/5; 58/100] END ...C=9, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 58/100] START C=9, gamma=83, kernel=rbf................................\n[CV 2/5; 58/100] END ...C=9, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 58/100] START C=9, gamma=83, kernel=rbf................................\n[CV 3/5; 58/100] END ...C=9, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 58/100] START C=9, gamma=83, kernel=rbf................................\n[CV 4/5; 58/100] END ...C=9, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 58/100] START C=9, gamma=83, kernel=rbf................................\n[CV 5/5; 58/100] END ...C=9, gamma=83, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 59/100] START C=56, gamma=86, kernel=poly..............................\n[CV 1/5; 59/100] END .C=56, gamma=86, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 59/100] START C=56, gamma=86, kernel=poly..............................\n[CV 2/5; 59/100] END .C=56, gamma=86, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 59/100] START C=56, gamma=86, kernel=poly..............................\n[CV 3/5; 59/100] END .C=56, gamma=86, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 59/100] START C=56, gamma=86, kernel=poly..............................\n[CV 4/5; 59/100] END .C=56, gamma=86, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 59/100] START C=56, gamma=86, kernel=poly..............................\n[CV 5/5; 59/100] END .C=56, gamma=86, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 60/100] START C=90, gamma=99, kernel=rbf...............................\n[CV 1/5; 60/100] END ..C=90, gamma=99, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 60/100] START C=90, gamma=99, kernel=rbf...............................\n[CV 2/5; 60/100] END ..C=90, gamma=99, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 60/100] START C=90, gamma=99, kernel=rbf...............................\n[CV 3/5; 60/100] END ..C=90, gamma=99, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 60/100] START C=90, gamma=99, kernel=rbf...............................\n[CV 4/5; 60/100] END ..C=90, gamma=99, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 60/100] START C=90, gamma=99, kernel=rbf...............................\n[CV 5/5; 60/100] END ..C=90, gamma=99, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 61/100] START C=36, gamma=68, kernel=linear............................\n[CV 1/5; 61/100] END C=36, gamma=68, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 61/100] START C=36, gamma=68, kernel=linear............................\n[CV 2/5; 61/100] END C=36, gamma=68, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 61/100] START C=36, gamma=68, kernel=linear............................\n[CV 3/5; 61/100] END C=36, gamma=68, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 61/100] START C=36, gamma=68, kernel=linear............................\n[CV 4/5; 61/100] END C=36, gamma=68, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 61/100] START C=36, gamma=68, kernel=linear............................\n[CV 5/5; 61/100] END C=36, gamma=68, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 62/100] START C=67, gamma=36, kernel=poly..............................\n[CV 1/5; 62/100] END .C=67, gamma=36, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 62/100] START C=67, gamma=36, kernel=poly..............................\n[CV 2/5; 62/100] END .C=67, gamma=36, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 62/100] START C=67, gamma=36, kernel=poly..............................\n[CV 3/5; 62/100] END .C=67, gamma=36, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 62/100] START C=67, gamma=36, kernel=poly..............................\n[CV 4/5; 62/100] END .C=67, gamma=36, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 62/100] START C=67, gamma=36, kernel=poly..............................\n[CV 5/5; 62/100] END .C=67, gamma=36, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 63/100] START C=55, gamma=43, kernel=rbf...............................\n"},"5":{"name":"stdout","output_type":"stream","text":"[CV 1/5; 63/100] END ..C=55, gamma=43, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 63/100] START C=55, gamma=43, kernel=rbf...............................\n[CV 2/5; 63/100] END ..C=55, gamma=43, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 63/100] START C=55, gamma=43, kernel=rbf...............................\n[CV 3/5; 63/100] END ..C=55, gamma=43, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 63/100] START C=55, gamma=43, kernel=rbf...............................\n[CV 4/5; 63/100] END ..C=55, gamma=43, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 63/100] START C=55, gamma=43, kernel=rbf...............................\n[CV 5/5; 63/100] END ..C=55, gamma=43, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 64/100] START C=63, gamma=52, kernel=linear............................\n[CV 1/5; 64/100] END C=63, gamma=52, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 64/100] START C=63, gamma=52, kernel=linear............................\n[CV 2/5; 64/100] END C=63, gamma=52, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 64/100] START C=63, gamma=52, kernel=linear............................\n[CV 3/5; 64/100] END C=63, gamma=52, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 64/100] START C=63, gamma=52, kernel=linear............................\n[CV 4/5; 64/100] END C=63, gamma=52, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 64/100] START C=63, gamma=52, kernel=linear............................\n[CV 5/5; 64/100] END C=63, gamma=52, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 65/100] START C=40, gamma=98, kernel=poly..............................\n[CV 1/5; 65/100] END .C=40, gamma=98, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 65/100] START C=40, gamma=98, kernel=poly..............................\n[CV 2/5; 65/100] END .C=40, gamma=98, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 65/100] START C=40, gamma=98, kernel=poly..............................\n[CV 3/5; 65/100] END .C=40, gamma=98, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 65/100] START C=40, gamma=98, kernel=poly..............................\n[CV 4/5; 65/100] END .C=40, gamma=98, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 65/100] START C=40, gamma=98, kernel=poly..............................\n[CV 5/5; 65/100] END .C=40, gamma=98, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 66/100] START C=68, gamma=43, kernel=linear............................\n[CV 1/5; 66/100] END C=68, gamma=43, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 66/100] START C=68, gamma=43, kernel=linear............................\n[CV 2/5; 66/100] END C=68, gamma=43, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 66/100] START C=68, gamma=43, kernel=linear............................\n[CV 3/5; 66/100] END C=68, gamma=43, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 66/100] START C=68, gamma=43, kernel=linear............................\n[CV 4/5; 66/100] END C=68, gamma=43, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 66/100] START C=68, gamma=43, kernel=linear............................\n[CV 5/5; 66/100] END C=68, gamma=43, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 67/100] START C=78, gamma=31, kernel=poly..............................\n[CV 1/5; 67/100] END .C=78, gamma=31, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 67/100] START C=78, gamma=31, kernel=poly..............................\n[CV 2/5; 67/100] END .C=78, gamma=31, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 67/100] START C=78, gamma=31, kernel=poly..............................\n[CV 3/5; 67/100] END .C=78, gamma=31, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 67/100] START C=78, gamma=31, kernel=poly..............................\n[CV 4/5; 67/100] END .C=78, gamma=31, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 67/100] START C=78, gamma=31, kernel=poly..............................\n[CV 5/5; 67/100] END .C=78, gamma=31, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 68/100] START C=49, gamma=45, kernel=linear............................\n[CV 1/5; 68/100] END C=49, gamma=45, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 68/100] START C=49, gamma=45, kernel=linear............................\n[CV 2/5; 68/100] END C=49, gamma=45, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 68/100] START C=49, gamma=45, kernel=linear............................\n[CV 3/5; 68/100] END C=49, gamma=45, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 68/100] START C=49, gamma=45, kernel=linear............................\n[CV 4/5; 68/100] END C=49, gamma=45, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 68/100] START C=49, gamma=45, kernel=linear............................\n[CV 5/5; 68/100] END C=49, gamma=45, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 69/100] START C=97, gamma=76, kernel=linear............................\n[CV 1/5; 69/100] END C=97, gamma=76, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 69/100] START C=97, gamma=76, kernel=linear............................\n[CV 2/5; 69/100] END C=97, gamma=76, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 69/100] START C=97, gamma=76, kernel=linear............................\n[CV 3/5; 69/100] END C=97, gamma=76, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 69/100] START C=97, gamma=76, kernel=linear............................\n[CV 4/5; 69/100] END C=97, gamma=76, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 69/100] START C=97, gamma=76, kernel=linear............................\n[CV 5/5; 69/100] END C=97, gamma=76, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 70/100] START C=60, gamma=16, kernel=linear............................\n[CV 1/5; 70/100] END C=60, gamma=16, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 70/100] START C=60, gamma=16, kernel=linear............................\n[CV 2/5; 70/100] END C=60, gamma=16, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 70/100] START C=60, gamma=16, kernel=linear............................\n[CV 3/5; 70/100] END C=60, gamma=16, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 70/100] START C=60, gamma=16, kernel=linear............................\n[CV 4/5; 70/100] END C=60, gamma=16, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 70/100] START C=60, gamma=16, kernel=linear............................\n[CV 5/5; 70/100] END C=60, gamma=16, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 71/100] START C=20, gamma=8, kernel=rbf................................\n[CV 1/5; 71/100] END ...C=20, gamma=8, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 71/100] START C=20, gamma=8, kernel=rbf................................\n[CV 2/5; 71/100] END ...C=20, gamma=8, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 71/100] START C=20, gamma=8, kernel=rbf................................\n[CV 3/5; 71/100] END ...C=20, gamma=8, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 71/100] START C=20, gamma=8, kernel=rbf................................\n[CV 4/5; 71/100] END ...C=20, gamma=8, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 71/100] START C=20, gamma=8, kernel=rbf................................\n[CV 5/5; 71/100] END ...C=20, gamma=8, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 72/100] START C=51, gamma=90, kernel=rbf...............................\n[CV 1/5; 72/100] END ..C=51, gamma=90, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 72/100] START C=51, gamma=90, kernel=rbf...............................\n[CV 2/5; 72/100] END ..C=51, gamma=90, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 72/100] START C=51, gamma=90, kernel=rbf...............................\n[CV 3/5; 72/100] END ..C=51, gamma=90, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 72/100] START C=51, gamma=90, kernel=rbf...............................\n[CV 4/5; 72/100] END ..C=51, gamma=90, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 72/100] START C=51, gamma=90, kernel=rbf...............................\n[CV 5/5; 72/100] END ..C=51, gamma=90, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 73/100] START C=54, gamma=52, kernel=rbf...............................\n[CV 1/5; 73/100] END ..C=54, gamma=52, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 73/100] START C=54, gamma=52, kernel=rbf...............................\n[CV 2/5; 73/100] END ..C=54, gamma=52, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 73/100] START C=54, gamma=52, kernel=rbf...............................\n[CV 3/5; 73/100] END ..C=54, gamma=52, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 73/100] START C=54, gamma=52, kernel=rbf...............................\n[CV 4/5; 73/100] END ..C=54, gamma=52, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 73/100] START C=54, gamma=52, kernel=rbf...............................\n[CV 5/5; 73/100] END ..C=54, gamma=52, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 74/100] START C=56, gamma=14, kernel=rbf...............................\n[CV 1/5; 74/100] END ..C=56, gamma=14, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 74/100] START C=56, gamma=14, kernel=rbf...............................\n[CV 2/5; 74/100] END ..C=56, gamma=14, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 74/100] START C=56, gamma=14, kernel=rbf...............................\n[CV 3/5; 74/100] END ..C=56, gamma=14, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 74/100] START C=56, gamma=14, kernel=rbf...............................\n[CV 4/5; 74/100] END ..C=56, gamma=14, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 74/100] START C=56, gamma=14, kernel=rbf...............................\n[CV 5/5; 74/100] END ..C=56, gamma=14, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 75/100] START C=90, gamma=63, kernel=poly..............................\n[CV 1/5; 75/100] END .C=90, gamma=63, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 75/100] START C=90, gamma=63, kernel=poly..............................\n[CV 2/5; 75/100] END .C=90, gamma=63, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 75/100] START C=90, gamma=63, kernel=poly..............................\n[CV 3/5; 75/100] END .C=90, gamma=63, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 75/100] START C=90, gamma=63, kernel=poly..............................\n[CV 4/5; 75/100] END .C=90, gamma=63, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 75/100] START C=90, gamma=63, kernel=poly..............................\n[CV 5/5; 75/100] END .C=90, gamma=63, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 76/100] START C=93, gamma=31, kernel=rbf...............................\n[CV 1/5; 76/100] END ..C=93, gamma=31, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 76/100] START C=93, gamma=31, kernel=rbf...............................\n[CV 2/5; 76/100] END ..C=93, gamma=31, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 76/100] START C=93, gamma=31, kernel=rbf...............................\n[CV 3/5; 76/100] END ..C=93, gamma=31, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 76/100] START C=93, gamma=31, kernel=rbf...............................\n[CV 4/5; 76/100] END ..C=93, gamma=31, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 76/100] START C=93, gamma=31, kernel=rbf...............................\n[CV 5/5; 76/100] END ..C=93, gamma=31, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 77/100] START C=92, gamma=75, kernel=linear............................\n[CV 1/5; 77/100] END C=92, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 77/100] START C=92, gamma=75, kernel=linear............................\n[CV 2/5; 77/100] END C=92, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 77/100] START C=92, gamma=75, kernel=linear............................\n[CV 3/5; 77/100] END C=92, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 77/100] START C=92, gamma=75, kernel=linear............................\n[CV 4/5; 77/100] END C=92, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 77/100] START C=92, gamma=75, kernel=linear............................\n[CV 5/5; 77/100] END C=92, gamma=75, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 78/100] START C=91, gamma=35, kernel=rbf...............................\n[CV 1/5; 78/100] END ..C=91, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 78/100] START C=91, gamma=35, kernel=rbf...............................\n[CV 2/5; 78/100] END ..C=91, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 78/100] START C=91, gamma=35, kernel=rbf...............................\n[CV 3/5; 78/100] END ..C=91, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 78/100] START C=91, gamma=35, kernel=rbf...............................\n[CV 4/5; 78/100] END ..C=91, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 78/100] START C=91, gamma=35, kernel=rbf...............................\n[CV 5/5; 78/100] END ..C=91, gamma=35, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 79/100] START C=6, gamma=34, kernel=sigmoid............................\n[CV 1/5; 79/100] END C=6, gamma=34, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 79/100] START C=6, gamma=34, kernel=sigmoid............................\n[CV 2/5; 79/100] END C=6, gamma=34, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 79/100] START C=6, gamma=34, kernel=sigmoid............................\n[CV 3/5; 79/100] END C=6, gamma=34, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 79/100] START C=6, gamma=34, kernel=sigmoid............................\n"},"6":{"name":"stdout","output_type":"stream","text":"[CV 4/5; 79/100] END C=6, gamma=34, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 79/100] START C=6, gamma=34, kernel=sigmoid............................\n[CV 5/5; 79/100] END C=6, gamma=34, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 80/100] START C=71, gamma=43, kernel=sigmoid...........................\n[CV 1/5; 80/100] END C=71, gamma=43, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 80/100] START C=71, gamma=43, kernel=sigmoid...........................\n[CV 2/5; 80/100] END C=71, gamma=43, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 80/100] START C=71, gamma=43, kernel=sigmoid...........................\n[CV 3/5; 80/100] END C=71, gamma=43, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 80/100] START C=71, gamma=43, kernel=sigmoid...........................\n[CV 4/5; 80/100] END C=71, gamma=43, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 80/100] START C=71, gamma=43, kernel=sigmoid...........................\n[CV 5/5; 80/100] END C=71, gamma=43, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 81/100] START C=27, gamma=72, kernel=poly..............................\n[CV 1/5; 81/100] END .C=27, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 81/100] START C=27, gamma=72, kernel=poly..............................\n[CV 2/5; 81/100] END .C=27, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 81/100] START C=27, gamma=72, kernel=poly..............................\n[CV 3/5; 81/100] END .C=27, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 81/100] START C=27, gamma=72, kernel=poly..............................\n[CV 4/5; 81/100] END .C=27, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 81/100] START C=27, gamma=72, kernel=poly..............................\n[CV 5/5; 81/100] END .C=27, gamma=72, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 82/100] START C=44, gamma=35, kernel=poly..............................\n[CV 1/5; 82/100] END .C=44, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 82/100] START C=44, gamma=35, kernel=poly..............................\n[CV 2/5; 82/100] END .C=44, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 82/100] START C=44, gamma=35, kernel=poly..............................\n[CV 3/5; 82/100] END .C=44, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 82/100] START C=44, gamma=35, kernel=poly..............................\n[CV 4/5; 82/100] END .C=44, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 82/100] START C=44, gamma=35, kernel=poly..............................\n[CV 5/5; 82/100] END .C=44, gamma=35, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 83/100] START C=11, gamma=39, kernel=rbf...............................\n[CV 1/5; 83/100] END ..C=11, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 83/100] START C=11, gamma=39, kernel=rbf...............................\n[CV 2/5; 83/100] END ..C=11, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 83/100] START C=11, gamma=39, kernel=rbf...............................\n[CV 3/5; 83/100] END ..C=11, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 83/100] START C=11, gamma=39, kernel=rbf...............................\n[CV 4/5; 83/100] END ..C=11, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 83/100] START C=11, gamma=39, kernel=rbf...............................\n[CV 5/5; 83/100] END ..C=11, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 84/100] START C=81, gamma=25, kernel=rbf...............................\n[CV 1/5; 84/100] END ..C=81, gamma=25, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 84/100] START C=81, gamma=25, kernel=rbf...............................\n[CV 2/5; 84/100] END ..C=81, gamma=25, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 84/100] START C=81, gamma=25, kernel=rbf...............................\n[CV 3/5; 84/100] END ..C=81, gamma=25, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 84/100] START C=81, gamma=25, kernel=rbf...............................\n[CV 4/5; 84/100] END ..C=81, gamma=25, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 84/100] START C=81, gamma=25, kernel=rbf...............................\n[CV 5/5; 84/100] END ..C=81, gamma=25, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 85/100] START C=47, gamma=54, kernel=linear............................\n[CV 1/5; 85/100] END C=47, gamma=54, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 85/100] START C=47, gamma=54, kernel=linear............................\n[CV 2/5; 85/100] END C=47, gamma=54, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 85/100] START C=47, gamma=54, kernel=linear............................\n[CV 3/5; 85/100] END C=47, gamma=54, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 85/100] START C=47, gamma=54, kernel=linear............................\n[CV 4/5; 85/100] END C=47, gamma=54, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 85/100] START C=47, gamma=54, kernel=linear............................\n[CV 5/5; 85/100] END C=47, gamma=54, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 86/100] START C=7, gamma=96, kernel=linear.............................\n[CV 1/5; 86/100] END C=7, gamma=96, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 86/100] START C=7, gamma=96, kernel=linear.............................\n[CV 2/5; 86/100] END C=7, gamma=96, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 86/100] START C=7, gamma=96, kernel=linear.............................\n[CV 3/5; 86/100] END C=7, gamma=96, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 86/100] START C=7, gamma=96, kernel=linear.............................\n[CV 4/5; 86/100] END C=7, gamma=96, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 86/100] START C=7, gamma=96, kernel=linear.............................\n[CV 5/5; 86/100] END C=7, gamma=96, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 87/100] START C=80, gamma=90, kernel=linear............................\n[CV 1/5; 87/100] END C=80, gamma=90, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 87/100] START C=80, gamma=90, kernel=linear............................\n[CV 2/5; 87/100] END C=80, gamma=90, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 87/100] START C=80, gamma=90, kernel=linear............................\n[CV 3/5; 87/100] END C=80, gamma=90, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 87/100] START C=80, gamma=90, kernel=linear............................\n[CV 4/5; 87/100] END C=80, gamma=90, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 87/100] START C=80, gamma=90, kernel=linear............................\n[CV 5/5; 87/100] END C=80, gamma=90, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 88/100] START C=36, gamma=37, kernel=sigmoid...........................\n[CV 1/5; 88/100] END C=36, gamma=37, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 88/100] START C=36, gamma=37, kernel=sigmoid...........................\n[CV 2/5; 88/100] END C=36, gamma=37, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 88/100] START C=36, gamma=37, kernel=sigmoid...........................\n[CV 3/5; 88/100] END C=36, gamma=37, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 88/100] START C=36, gamma=37, kernel=sigmoid...........................\n[CV 4/5; 88/100] END C=36, gamma=37, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 88/100] START C=36, gamma=37, kernel=sigmoid...........................\n[CV 5/5; 88/100] END C=36, gamma=37, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 89/100] START C=19, gamma=58, kernel=linear............................\n[CV 1/5; 89/100] END C=19, gamma=58, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 89/100] START C=19, gamma=58, kernel=linear............................\n[CV 2/5; 89/100] END C=19, gamma=58, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 89/100] START C=19, gamma=58, kernel=linear............................\n[CV 3/5; 89/100] END C=19, gamma=58, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 89/100] START C=19, gamma=58, kernel=linear............................\n[CV 4/5; 89/100] END C=19, gamma=58, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 89/100] START C=19, gamma=58, kernel=linear............................\n[CV 5/5; 89/100] END C=19, gamma=58, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 90/100] START C=59, gamma=28, kernel=poly..............................\n[CV 1/5; 90/100] END .C=59, gamma=28, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 90/100] START C=59, gamma=28, kernel=poly..............................\n[CV 2/5; 90/100] END .C=59, gamma=28, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 90/100] START C=59, gamma=28, kernel=poly..............................\n[CV 3/5; 90/100] END .C=59, gamma=28, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 90/100] START C=59, gamma=28, kernel=poly..............................\n[CV 4/5; 90/100] END .C=59, gamma=28, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 90/100] START C=59, gamma=28, kernel=poly..............................\n[CV 5/5; 90/100] END .C=59, gamma=28, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 91/100] START C=49, gamma=71, kernel=sigmoid...........................\n[CV 1/5; 91/100] END C=49, gamma=71, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 91/100] START C=49, gamma=71, kernel=sigmoid...........................\n[CV 2/5; 91/100] END C=49, gamma=71, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 91/100] START C=49, gamma=71, kernel=sigmoid...........................\n[CV 3/5; 91/100] END C=49, gamma=71, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 91/100] START C=49, gamma=71, kernel=sigmoid...........................\n[CV 4/5; 91/100] END C=49, gamma=71, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 91/100] START C=49, gamma=71, kernel=sigmoid...........................\n[CV 5/5; 91/100] END C=49, gamma=71, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 92/100] START C=4, gamma=33, kernel=rbf................................\n[CV 1/5; 92/100] END ...C=4, gamma=33, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 92/100] START C=4, gamma=33, kernel=rbf................................\n[CV 2/5; 92/100] END ...C=4, gamma=33, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 92/100] START C=4, gamma=33, kernel=rbf................................\n[CV 3/5; 92/100] END ...C=4, gamma=33, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 92/100] START C=4, gamma=33, kernel=rbf................................\n[CV 4/5; 92/100] END ...C=4, gamma=33, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 92/100] START C=4, gamma=33, kernel=rbf................................\n[CV 5/5; 92/100] END ...C=4, gamma=33, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 93/100] START C=17, gamma=18, kernel=rbf...............................\n[CV 1/5; 93/100] END ..C=17, gamma=18, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 93/100] START C=17, gamma=18, kernel=rbf...............................\n[CV 2/5; 93/100] END ..C=17, gamma=18, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 93/100] START C=17, gamma=18, kernel=rbf...............................\n[CV 3/5; 93/100] END ..C=17, gamma=18, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 93/100] START C=17, gamma=18, kernel=rbf...............................\n[CV 4/5; 93/100] END ..C=17, gamma=18, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 93/100] START C=17, gamma=18, kernel=rbf...............................\n[CV 5/5; 93/100] END ..C=17, gamma=18, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 94/100] START C=80, gamma=17, kernel=linear............................\n[CV 1/5; 94/100] END C=80, gamma=17, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 94/100] START C=80, gamma=17, kernel=linear............................\n[CV 2/5; 94/100] END C=80, gamma=17, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 94/100] START C=80, gamma=17, kernel=linear............................\n[CV 3/5; 94/100] END C=80, gamma=17, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 94/100] START C=80, gamma=17, kernel=linear............................\n[CV 4/5; 94/100] END C=80, gamma=17, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 94/100] START C=80, gamma=17, kernel=linear............................\n[CV 5/5; 94/100] END C=80, gamma=17, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 95/100] START C=47, gamma=89, kernel=sigmoid...........................\n[CV 1/5; 95/100] END C=47, gamma=89, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 95/100] START C=47, gamma=89, kernel=sigmoid...........................\n[CV 2/5; 95/100] END C=47, gamma=89, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 95/100] START C=47, gamma=89, kernel=sigmoid...........................\n[CV 3/5; 95/100] END C=47, gamma=89, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 95/100] START C=47, gamma=89, kernel=sigmoid...........................\n[CV 4/5; 95/100] END C=47, gamma=89, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 95/100] START C=47, gamma=89, kernel=sigmoid...........................\n[CV 5/5; 95/100] END C=47, gamma=89, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 96/100] START C=62, gamma=21, kernel=sigmoid...........................\n[CV 1/5; 96/100] END C=62, gamma=21, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 2/5; 96/100] START C=62, gamma=21, kernel=sigmoid...........................\n"},"7":{"name":"stdout","output_type":"stream","text":"[CV 2/5; 96/100] END C=62, gamma=21, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 3/5; 96/100] START C=62, gamma=21, kernel=sigmoid...........................\n[CV 3/5; 96/100] END C=62, gamma=21, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 4/5; 96/100] START C=62, gamma=21, kernel=sigmoid...........................\n[CV 4/5; 96/100] END C=62, gamma=21, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 5/5; 96/100] START C=62, gamma=21, kernel=sigmoid...........................\n[CV 5/5; 96/100] END C=62, gamma=21, kernel=sigmoid;, score=nan total time=   0.0s\n[CV 1/5; 97/100] START C=29, gamma=89, kernel=linear............................\n[CV 1/5; 97/100] END C=29, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 97/100] START C=29, gamma=89, kernel=linear............................\n[CV 2/5; 97/100] END C=29, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 97/100] START C=29, gamma=89, kernel=linear............................\n[CV 3/5; 97/100] END C=29, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 97/100] START C=29, gamma=89, kernel=linear............................\n[CV 4/5; 97/100] END C=29, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 97/100] START C=29, gamma=89, kernel=linear............................\n[CV 5/5; 97/100] END C=29, gamma=89, kernel=linear;, score=nan total time=   0.0s\n[CV 1/5; 98/100] START C=22, gamma=39, kernel=rbf...............................\n[CV 1/5; 98/100] END ..C=22, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 2/5; 98/100] START C=22, gamma=39, kernel=rbf...............................\n[CV 2/5; 98/100] END ..C=22, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 3/5; 98/100] START C=22, gamma=39, kernel=rbf...............................\n[CV 3/5; 98/100] END ..C=22, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 4/5; 98/100] START C=22, gamma=39, kernel=rbf...............................\n[CV 4/5; 98/100] END ..C=22, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 5/5; 98/100] START C=22, gamma=39, kernel=rbf...............................\n[CV 5/5; 98/100] END ..C=22, gamma=39, kernel=rbf;, score=nan total time=   0.0s\n[CV 1/5; 99/100] START C=97, gamma=11, kernel=poly..............................\n[CV 1/5; 99/100] END .C=97, gamma=11, kernel=poly;, score=nan total time=   0.0s\n[CV 2/5; 99/100] START C=97, gamma=11, kernel=poly..............................\n[CV 2/5; 99/100] END .C=97, gamma=11, kernel=poly;, score=nan total time=   0.0s\n[CV 3/5; 99/100] START C=97, gamma=11, kernel=poly..............................\n[CV 3/5; 99/100] END .C=97, gamma=11, kernel=poly;, score=nan total time=   0.0s\n[CV 4/5; 99/100] START C=97, gamma=11, kernel=poly..............................\n[CV 4/5; 99/100] END .C=97, gamma=11, kernel=poly;, score=nan total time=   0.0s\n[CV 5/5; 99/100] START C=97, gamma=11, kernel=poly..............................\n[CV 5/5; 99/100] END .C=97, gamma=11, kernel=poly;, score=nan total time=   0.0s\n[CV 1/5; 100/100] START C=55, gamma=23, kernel=linear...........................\n[CV 1/5; 100/100] END C=55, gamma=23, kernel=linear;, score=nan total time=   0.0s\n[CV 2/5; 100/100] START C=55, gamma=23, kernel=linear...........................\n[CV 2/5; 100/100] END C=55, gamma=23, kernel=linear;, score=nan total time=   0.0s\n[CV 3/5; 100/100] START C=55, gamma=23, kernel=linear...........................\n[CV 3/5; 100/100] END C=55, gamma=23, kernel=linear;, score=nan total time=   0.0s\n[CV 4/5; 100/100] START C=55, gamma=23, kernel=linear...........................\n[CV 4/5; 100/100] END C=55, gamma=23, kernel=linear;, score=nan total time=   0.0s\n[CV 5/5; 100/100] START C=55, gamma=23, kernel=linear...........................\n[CV 5/5; 100/100] END C=55, gamma=23, kernel=linear;, score=nan total time=   0.0s\n"},"8":{"ename":"ValueError","evalue":"\nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'M'\n\n--------------------------------------------------------------------------------\n400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'F'\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m rand_list \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     16\u001b[0m rand_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(mdl, rand_list, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mrand_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m rand_search\u001b[38;5;241m.\u001b[39mbest_params_\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1749\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1748\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1749\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: \nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'M'\n\n--------------------------------------------------------------------------------\n400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'F'\n"]}},"pos":45,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"ec9934","input":"lr_clf.coef_","output":{"0":{"data":{"text/plain":"array([[-0.05035417,  0.52130825,  0.70399177,  0.08542451, -0.25692624,\n         0.46711163,  0.05839025, -0.28834911,  0.56634088,  0.36548402,\n         1.0337979 ]])"},"exec_count":17,"output_type":"execute_result"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"8ab8da","input":"lr_clf.intercept_","output":{"0":{"data":{"text/plain":"array([0.33897953])"},"exec_count":19,"output_type":"execute_result"}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"33efbc","input":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport numpy\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import neighbors, datasets\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"b0ceee","input":"heart_df.columns","output":{"0":{"data":{"text/plain":"Index(['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS',\n       'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope',\n       'HeartDisease'],\n      dtype='object')"},"exec_count":21,"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"f23984","input":"y_hat = my_SVC_model.predict(x_test)\ntotal_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)","output":{"0":{"ename":"ValueError","evalue":"could not convert string to float: 'F'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmy_SVC_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m total_squared_error \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39msum((y_test \u001b[38;5;241m-\u001b[39m y_hat)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;66;03m#get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m mean_squared_error \u001b[38;5;241m=\u001b[39m total_squared_error\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_test) \u001b[38;5;66;03m#divide this by how many rows/observations we have \u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py:810\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    808\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    608\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 611\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix(X):\n\u001b[1;32m    621\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'F'"]}},"pos":47,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"0dff3f","input":"x_train","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>334</th>\n      <td>51</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>130</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Normal</td>\n      <td>170</td>\n      <td>N</td>\n      <td>-0.7</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>110</td>\n      <td>167</td>\n      <td>0</td>\n      <td>LVH</td>\n      <td>114</td>\n      <td>Y</td>\n      <td>2.0</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>59</td>\n      <td>F</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>188</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>124</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>700</th>\n      <td>42</td>\n      <td>M</td>\n      <td>TA</td>\n      <td>148</td>\n      <td>244</td>\n      <td>0</td>\n      <td>LVH</td>\n      <td>178</td>\n      <td>N</td>\n      <td>0.8</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>661</th>\n      <td>49</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>118</td>\n      <td>149</td>\n      <td>0</td>\n      <td>LVH</td>\n      <td>126</td>\n      <td>N</td>\n      <td>0.8</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>59</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>287</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>150</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>61</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>150</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>117</td>\n      <td>Y</td>\n      <td>2.0</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>48</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>160</td>\n      <td>329</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>92</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>41</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>112</td>\n      <td>268</td>\n      <td>0</td>\n      <td>LVH</td>\n      <td>172</td>\n      <td>Y</td>\n      <td>0.0</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>62</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>115</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Normal</td>\n      <td>128</td>\n      <td>Y</td>\n      <td>2.5</td>\n      <td>Down</td>\n    </tr>\n  </tbody>\n</table>\n<p>734 rows  11 columns</p>\n</div>","text/plain":"     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n334   51   M           ASY        130            0          1     Normal   \n762   40   M           ASY        110          167          0        LVH   \n110   59   F           ATA        130          188          0     Normal   \n700   42   M            TA        148          244          0        LVH   \n661   49   M           NAP        118          149          0        LVH   \n..   ...  ..           ...        ...          ...        ...        ...   \n177   59   M           ATA        140          287          0     Normal   \n366   61   M           ASY        150            0          0     Normal   \n93    48   M           ASY        160          329          0     Normal   \n764   41   F           NAP        112          268          0        LVH   \n323   62   M           ASY        115            0          1     Normal   \n\n     MaxHR ExerciseAngina  Oldpeak ST_Slope  \n334    170              N     -0.7       Up  \n762    114              Y      2.0     Flat  \n110    124              N      1.0     Flat  \n700    178              N      0.8       Up  \n661    126              N      0.8       Up  \n..     ...            ...      ...      ...  \n177    150              N      0.0       Up  \n366    117              Y      2.0     Flat  \n93      92              Y      1.5     Flat  \n764    172              Y      0.0       Up  \n323    128              Y      2.5     Down  \n\n[734 rows x 11 columns]"},"exec_count":25,"output_type":"execute_result"}},"pos":42,"type":"cell"}
{"cell_type":"code","exec_count":26,"id":"d79a2c","input":"svc_pred","output":{"0":{"ename":"NameError","evalue":"name 'svc_pred' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msvc_pred\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'svc_pred' is not defined"]}},"pos":44,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"458d0b","input":"svc_clf = svc()\nsvc_clf.fit(x_train, y_train)\nsvc_pred = svc_clf.predict(x_test)\nprec = precision_score(y_test, svc_pred)\nprint(prec)","output":{"0":{"ename":"ValueError","evalue":"could not convert string to float: 'M'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m svc_clf \u001b[38;5;241m=\u001b[39m svc()\n\u001b[0;32m----> 2\u001b[0m \u001b[43msvc_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m svc_pred \u001b[38;5;241m=\u001b[39m svc_clf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      4\u001b[0m prec \u001b[38;5;241m=\u001b[39m precision_score(y_test, svc_pred)\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    186\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M'"]}},"pos":43,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"cfe551","input":"# SVC Model\n\n#configuring the data\ntarget = heart_df['HeartDisease']\ninput_columns = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\n\n#splitting the data\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2)\n\nx_train.shape","output":{"0":{"data":{"text/plain":"(734, 11)"},"exec_count":29,"output_type":"execute_result"}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"57885a","input":"np.arange(60,100, 5)","output":{"0":{"data":{"text/plain":"array([60, 65, 70, 75, 80, 85, 90, 95])"},"exec_count":3,"output_type":"execute_result"}},"pos":2,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"b814ee","input":"from sklearn.svm import SVC\n\n#changing the kernel\nmy_SVC_model = SVC(kernel = 'rbf')\n\n#fitting the model\nmy_SVC_model.fit(x_train, y_train)","output":{"0":{"ename":"ValueError","evalue":"could not convert string to float: 'M'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m my_SVC_model \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#fitting the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmy_SVC_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    186\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M'"]}},"pos":36,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"f76d80","input":"from sklearn.svm import SVC\n\n#changing the kernel\nmy_SVC_model = SVC(kernel = 'linear', 'c' = 9, 'gamma' = 96)\n\n#fitting the model\nmy_SVC_model.fit(x_train, y_train)","output":{"0":{"ename":"SyntaxError","evalue":"expression cannot contain assignment, perhaps you meant \"==\"? (647793332.py, line 4)","output_type":"error","traceback":["\u001b[0;36m  Input \u001b[0;32mIn [31]\u001b[0;36m\u001b[0m\n\u001b[0;31m    my_SVC_model = SVC(kernel = 'linear', 'c' = 9, 'gamma' = 96)\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"]}},"pos":46,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"2a6364","input":"heart_df = pd.read_csv(\"data/heart.csv\")\nheart_df\n","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>172</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>156</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>ST</td>\n      <td>98</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>108</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>122</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>45</td>\n      <td>M</td>\n      <td>TA</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>132</td>\n      <td>N</td>\n      <td>1.2</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>68</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>Normal</td>\n      <td>141</td>\n      <td>N</td>\n      <td>3.4</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>57</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>115</td>\n      <td>Y</td>\n      <td>1.2</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>57</td>\n      <td>F</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>LVH</td>\n      <td>174</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>38</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>138</td>\n      <td>175</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>173</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows  12 columns</p>\n</div>","text/plain":"     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n0     40   M           ATA        140          289          0     Normal   \n1     49   F           NAP        160          180          0     Normal   \n2     37   M           ATA        130          283          0         ST   \n3     48   F           ASY        138          214          0     Normal   \n4     54   M           NAP        150          195          0     Normal   \n..   ...  ..           ...        ...          ...        ...        ...   \n913   45   M            TA        110          264          0     Normal   \n914   68   M           ASY        144          193          1     Normal   \n915   57   M           ASY        130          131          0     Normal   \n916   57   F           ATA        130          236          0        LVH   \n917   38   M           NAP        138          175          0     Normal   \n\n     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n0      172              N      0.0       Up             0  \n1      156              N      1.0     Flat             1  \n2       98              N      0.0       Up             0  \n3      108              Y      1.5     Flat             1  \n4      122              N      0.0       Up             0  \n..     ...            ...      ...      ...           ...  \n913    132              N      1.2     Flat             1  \n914    141              N      3.4     Flat             1  \n915    115              Y      1.2     Flat             1  \n916    174              N      0.0     Flat             1  \n917    173              N      0.0       Up             0  \n\n[918 rows x 12 columns]"},"exec_count":4,"output_type":"execute_result"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"f2ef38","input":"#heart_df['female'] = heart_df['female'].map({'F': 1, 'M': 0})\nheart_df['Sex'].replace('F',0 ,inplace=True)\nheart_df['Sex'].replace('M', 1,inplace=True)\n#Female is 0\n#Male is 1\n\n#ATA is 0\n#NAP is 1\n#ASY is 2\n#TA is 3\nheart_df['ChestPainType'].replace('ATA',0 ,inplace=True)\nheart_df['ChestPainType'].replace('NAP',1 ,inplace=True)\nheart_df['ChestPainType'].replace('ASY',2 ,inplace=True)\nheart_df['ChestPainType'].replace('TA',3 ,inplace=True)\n\n#Normal is 0\n#St is 1\n#LVH is 2\nheart_df['RestingECG'].replace('Normal',0, inplace=True)\nheart_df['RestingECG'].replace('ST',1, inplace=True)\nheart_df['RestingECG'].replace('LVH',2, inplace=True)\n\n#No is 0\n#Yes is 1\nheart_df['ExerciseAngina'].replace('N',0 ,inplace=True)\nheart_df['ExerciseAngina'].replace('Y',1 ,inplace=True)\n\n#ST_Slope\n#Up is 0\n#Flat is 1\n#Down is 2\nheart_df['ST_Slope'].replace('Up', 0, inplace = True)\nheart_df['ST_Slope'].replace('Flat', 1, inplace = True)\nheart_df['ST_Slope'].replace('Down', 2, inplace = True)\n\nheart_df.head() #worky :)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>0</td>\n      <td>1</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>156</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>1</td>\n      <td>98</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>0</td>\n      <td>2</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>0</td>\n      <td>122</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n0   40    1              0        140          289          0           0   \n1   49    0              1        160          180          0           0   \n2   37    1              0        130          283          0           1   \n3   48    0              2        138          214          0           0   \n4   54    1              1        150          195          0           0   \n\n   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n0    172               0      0.0         0             0  \n1    156               0      1.0         1             1  \n2     98               0      0.0         0             0  \n3    108               1      1.5         1             1  \n4    122               0      0.0         0             0  "},"exec_count":4,"output_type":"execute_result"}},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"f04687","input":"heart_df.dropna(inplace=True)\nheart_df.shape","output":{"0":{"data":{"text/plain":"(918, 12)"},"exec_count":5,"output_type":"execute_result"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"5715dd","input":"scores = {}\nscores['metrics'] = {'accuracy': 'accuracy', 'precision':'precision', 'recall':'recall', 'f1_score':'f1_score'}","pos":8,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"0bf3c5","input":"x_test","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>391</th>\n      <td>70</td>\n      <td>1</td>\n      <td>2</td>\n      <td>115</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>92</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>42</td>\n      <td>1</td>\n      <td>2</td>\n      <td>140</td>\n      <td>358</td>\n      <td>0</td>\n      <td>0</td>\n      <td>170</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>36</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>160</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>521</th>\n      <td>61</td>\n      <td>1</td>\n      <td>2</td>\n      <td>120</td>\n      <td>282</td>\n      <td>0</td>\n      <td>1</td>\n      <td>135</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>834</th>\n      <td>44</td>\n      <td>1</td>\n      <td>0</td>\n      <td>120</td>\n      <td>220</td>\n      <td>0</td>\n      <td>0</td>\n      <td>170</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>663</th>\n      <td>66</td>\n      <td>1</td>\n      <td>0</td>\n      <td>160</td>\n      <td>246</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>53</td>\n      <td>1</td>\n      <td>2</td>\n      <td>144</td>\n      <td>300</td>\n      <td>1</td>\n      <td>1</td>\n      <td>128</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>426</th>\n      <td>56</td>\n      <td>1</td>\n      <td>0</td>\n      <td>126</td>\n      <td>166</td>\n      <td>0</td>\n      <td>1</td>\n      <td>140</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>523</th>\n      <td>59</td>\n      <td>1</td>\n      <td>2</td>\n      <td>124</td>\n      <td>160</td>\n      <td>0</td>\n      <td>0</td>\n      <td>117</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>546</th>\n      <td>48</td>\n      <td>1</td>\n      <td>1</td>\n      <td>132</td>\n      <td>220</td>\n      <td>1</td>\n      <td>1</td>\n      <td>162</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>276 rows  11 columns</p>\n</div>","text/plain":"     Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n391   70    1              2        115            0          0           1   \n284   42    1              2        140          358          0           0   \n257   36    1              1        150          160          0           0   \n521   61    1              2        120          282          0           1   \n834   44    1              0        120          220          0           0   \n..   ...  ...            ...        ...          ...        ...         ...   \n663   66    1              0        160          246          0           0   \n607   53    1              2        144          300          1           1   \n426   56    1              0        126          166          0           1   \n523   59    1              2        124          160          0           0   \n546   48    1              1        132          220          1           1   \n\n     MaxHR  ExerciseAngina  Oldpeak  ST_Slope  \n391     92               1      0.0         1  \n284    170               0      0.0         0  \n257    172               0      0.0         0  \n521    135               1      4.0         2  \n834    170               0      0.0         0  \n..     ...             ...      ...       ...  \n663    120               1      0.0         1  \n607    128               1      1.5         1  \n426    140               0      0.0         0  \n523    117               1      1.0         1  \n546    162               0      0.0         1  \n\n[276 rows x 11 columns]"},"exec_count":8,"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"markdown","id":"1de317","input":"grid search cv","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"3d6727","input":"Support Vector Classification Model uses two groups of data to categorize new data.  It does this by plotting the data onto a graph, and then using a hyperplane to split the data according to the group that the data belongs to. The hyper\\-parameters  that could be fine tuned are the Kernel, the C value, the Gamma value, and the Degree. I decided to use a RandomizedSearchCV to determine the best parameters.  When testing, for the best parameters, I ran into some problems. The first problem was how long it took too long to run the program. The program would run for about thirty minutes, and still not find a best fit for the graph. In response, I decided to decrease the amount of variables the RandomizedSearchCV needed to look for, and additionally, the range that each variable could search within. In the end, I decided that testing the C value, the Gamma value, and the Kernel would be most helpful in optimizing the model. According to my values the RandomizedSearchCV determine the best parameters was a Kernel of linear, a Gamma value of 96, and a C value of 9.\n\n","pos":50,"type":"cell"}
{"cell_type":"markdown","id":"594fc7","input":"The model is a logistic regression and it works by predicting whether someone has heart disease or if they do not. It classifies them into one of these two groups . We changed some parameters such as the weight, training and testing data. I think it performed well in predicting if someone has heart disease and classifying them into two groups. It does this by analyzing relationships between two independent variables. The coefficient of the linear regression model shows the relationship between the variables by multiplying it with a certain value and a higher/lower coefficient indicates which classification the data point would be predicted to be in.\n","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"c0d2b5","input":"","pos":28,"type":"cell"}
{"cell_type":"markdown","id":"c6a4b2","input":"Adaboost is an example of ensemble learning, where several basic algorithms are combined to make one more optimized algorithm. For example, with a decision tree, instead of hoping 1 decision tree can correctly guess a result, ensemble learning will take multiple decision trees and combine them together to create a stronger algorithm.\n\nAdaboost is also a sequential learning version of ensemble learning, where every model is made in order, and the newest model learns from the previous model's failures. It does this by \"boosting\", or reducing the error through methods such as increasing the weights of data that was mislabelled.\n\nHowever, Adaboost is extremely sensitive to noisy data and outliers, which is why it is highly recommended to remove outliers from data with Adaboost.\n\nHere, Adaboost was used on our heart disease dataset, with a mean squared error of 0.12 on our testing data, and an overall accuracy score of 0.880 and a precision score of 0.880. There were 13 false positives and 9 false negatives. This is a decent score for a machine learning model, but when it comes to diagnosis it probably isn't the best and there is certainly a more ideal model. \n","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"d38595","input":"**NOTE:** PLEASE save the scores to the score dictionary \n\nModels to try out:\n\n- Decision Tree \\(Emma\\)\n- Random Forest \\(Emma\\)\n- Adaboost\n- SVC\n- \n- NEURAL NETWORKS  Thomas\n- KNN\n- Logistic Regression \\(kenju\\)\n- Naive bayes\n- \n- \n- Naive Bayes \\(Rhone\\)\n- Adaboost \\(Jeffrey\\)\n- Support vector classifier \\(halli\\)\n- \n- Stochastic Gradient Descent Classifier \\(SGDClassifier\\)\n  - https://scikit\\-learn.org/stable/modules/generated/sklearn.linear\\_model.SGDClassifier.html\n- Support vector classifier \n- KNN \\(Rhone\\)\n- \n- \n\n<u>**AlSO TRY OPTIMIZING THEM**</u>\n\nGrid Search CV\n\nEvaluation metrics:\n\n- F1 score\n- Accuracy\n- Recall\n- Precision\n- Confusion matrix\n\n","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"e37112","input":"Gaussian Naive Bayes is for binary classification and assumes that all continuous data has normal distribution, and that all features are independent and equal from each other. The Naive Bayes finds the probability of the predicted outcome\\(y variable\\) given the x values and then classifies the point based on whether one of the classifications had a higher probability than the other classification. In order to optimize the function, I stratified the data, which raised the accuracy score from 0.83 to 0.885 while also scaling the data though that did not cause a change in the accuracy score or any of the other measures. The results ending up giving a accuracy score of 0.885, a precision score of 0.878, a recall score of 0.921, and an f1 score of 0.899. This resulted in 8 false negatives and 13 false positives out of 184 points in what I believe can be described as an accurate model.\n\n","pos":32,"type":"cell"}
{"cell_type":"markdown","id":"f8ef79","input":"The KNN nearest neighbors function looks for the k nearest neighbors of a point and their classification and then classifies the point based on the state of the nearest neighbors. Using GridSearchCV, I tried to optimize the value of the k nearest neighbors in a range from 1 to 400 and it was found that 23 was the most optimal number. It ended up giving a success rate of roughly 72.8 percent with 25 false positives and 25 false negative, 57 correct positives, and 77 correct negatives, a recall rate of 75.5 percent a precision rate of 75.5 percent, and an f1\\_score of 75.5 percent. These numbers would be described as a moderately \\-to good accurate model.\n\n","pos":18,"type":"cell"}
{"id":0,"time":1659462029563,"type":"user"}
{"last_load":1659471326755,"type":"file"}