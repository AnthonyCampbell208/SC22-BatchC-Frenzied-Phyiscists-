{"backend_state":"running","connection_file":"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/.local/share/jupyter/runtime/kernel-6b7bbcb9-2fc1-42f4-b8dc-9f138b49b582.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1659366671615,"exec_count":4,"id":"f2ef38","input":"#heart_df['female'] = heart_df['female'].map({'F': 1, 'M': 0})\nheart_df['Sex'].replace('F',0 ,inplace=True)\nheart_df['Sex'].replace('M', 1,inplace=True)\n#Female is 0\n#Male is 1\n\n#ATA is 0\n#NAP is 1\n#ASY is 2\n#TA is 3\nheart_df['ChestPainType'].replace('ATA',0 ,inplace=True)\nheart_df['ChestPainType'].replace('NAP',1 ,inplace=True)\nheart_df['ChestPainType'].replace('ASY',2 ,inplace=True)\nheart_df['ChestPainType'].replace('TA',3 ,inplace=True)\n\n#Normal is 0\n#St is 1\n#LVH is 2\nheart_df['RestingECG'].replace('Normal',0, inplace=True)\nheart_df['RestingECG'].replace('ST',1, inplace=True)\nheart_df['RestingECG'].replace('LVH',2, inplace=True)\n\n#No is 0\n#Yes is 1\nheart_df['ExerciseAngina'].replace('N',0 ,inplace=True)\nheart_df['ExerciseAngina'].replace('Y',1 ,inplace=True)\n\n#ST_Slope\n#Up is 0\n#Flat is 1\n#Down is 2\nheart_df['ST_Slope'].replace('Up', 0, inplace = True)\nheart_df['ST_Slope'].replace('Flat', 1, inplace = True)\nheart_df['ST_Slope'].replace('Down', 2, inplace = True)\n\nheart_df.head() #worky :)","kernel":"ds_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>0</td>\n      <td>1</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>156</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>1</td>\n      <td>98</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>0</td>\n      <td>2</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>0</td>\n      <td>122</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n0   40    1              0        140          289          0           0   \n1   49    0              1        160          180          0           0   \n2   37    1              0        130          283          0           1   \n3   48    0              2        138          214          0           0   \n4   54    1              1        150          195          0           0   \n\n   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n0    172               0      0.0         0             0  \n1    156               0      1.0         1             1  \n2     98               0      0.0         0             0  \n3    108               1      1.5         1             1  \n4    122               0      0.0         0             0  "},"exec_count":4}},"pos":4,"start":1659366671574,"state":"done","type":"cell"}
{"cell_type":"code","end":1659368527849,"exec_count":2,"id":"33efbc","input":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport numpy\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import neighbors, datasets\nfrom sklearn.feature_selection import VarianceThreshold","kernel":"ds_env","pos":1,"start":1659368526547,"state":"done","type":"cell"}
{"cell_type":"code","end":1659368529726,"exec_count":3,"id":"57885a","input":"np.arange(60,100, 5)","kernel":"ds_env","output":{"0":{"data":{"text/plain":"array([60, 65, 70, 75, 80, 85, 90, 95])"},"exec_count":3}},"pos":2,"start":1659368529705,"state":"done","type":"cell"}
{"cell_type":"code","end":1659368531790,"exec_count":4,"id":"2a6364","input":"heart_df = pd.read_csv(\"data/heart.csv\")\nheart_df\n","kernel":"ds_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>172</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>156</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>ST</td>\n      <td>98</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>108</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>122</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>45</td>\n      <td>M</td>\n      <td>TA</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>132</td>\n      <td>N</td>\n      <td>1.2</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>68</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>Normal</td>\n      <td>141</td>\n      <td>N</td>\n      <td>3.4</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>57</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>115</td>\n      <td>Y</td>\n      <td>1.2</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>57</td>\n      <td>F</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>LVH</td>\n      <td>174</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>38</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>138</td>\n      <td>175</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>173</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows Ã— 12 columns</p>\n</div>","text/plain":"     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n0     40   M           ATA        140          289          0     Normal   \n1     49   F           NAP        160          180          0     Normal   \n2     37   M           ATA        130          283          0         ST   \n3     48   F           ASY        138          214          0     Normal   \n4     54   M           NAP        150          195          0     Normal   \n..   ...  ..           ...        ...          ...        ...        ...   \n913   45   M            TA        110          264          0     Normal   \n914   68   M           ASY        144          193          1     Normal   \n915   57   M           ASY        130          131          0     Normal   \n916   57   F           ATA        130          236          0        LVH   \n917   38   M           NAP        138          175          0     Normal   \n\n     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n0      172              N      0.0       Up             0  \n1      156              N      1.0     Flat             1  \n2       98              N      0.0       Up             0  \n3      108              Y      1.5     Flat             1  \n4      122              N      0.0       Up             0  \n..     ...            ...      ...      ...           ...  \n913    132              N      1.2     Flat             1  \n914    141              N      3.4     Flat             1  \n915    115              Y      1.2     Flat             1  \n916    174              N      0.0     Flat             1  \n917    173              N      0.0       Up             0  \n\n[918 rows x 12 columns]"},"exec_count":4}},"pos":3,"start":1659368531763,"state":"done","type":"cell"}
{"cell_type":"code","end":1659368542789,"exec_count":5,"id":"f04687","input":"heart_df.dropna(inplace=True)\nheart_df.shape","kernel":"ds_env","output":{"0":{"data":{"text/plain":"(918, 12)"},"exec_count":5}},"pos":5,"start":1659368542772,"state":"done","type":"cell"}
{"cell_type":"code","end":1659368555513,"exec_count":6,"id":"cfe551","input":"# SVC Model\n\n#configuring the data\ntarget = heart_df['HeartDisease']\ninput_columns = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\n\n#splitting the data\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2, random_state = 45)\n\nx_train.shape","kernel":"ds_env","output":{"0":{"data":{"text/plain":"(734, 11)"},"exec_count":6}},"pos":30,"start":1659368555502,"state":"done","type":"cell"}
{"cell_type":"code","end":1659369134437,"exec_count":16,"id":"1dc695","input":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.svm import SVC as svc\nfrom sklearn import preprocessing\nfrom scipy import stats\n\nmdl = svc()\n\nrand_list = {\"C\": stats.uniform(.1,100), 'gamma': stats.uniform(.1, 100), 'kernel': ('poly', 'linear', 'rbf', 'sigmoid')}\nrand_search = RandomizedSearchCV(mdl, rand_list, n_iter = 100, cv = 5, refit = True)\nrand_search.fit(x_train, y_train)\nrand_search.cv_results_","kernel":"ds_env","output":{"0":{"ename":"ValueError","evalue":"\nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'M'\n\n--------------------------------------------------------------------------------\n400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'F'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m rand_list \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m.1\u001b[39m,\u001b[38;5;241m100\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: stats\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m.1\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m      9\u001b[0m rand_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(mdl, rand_list, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, refit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrand_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m rand_search\u001b[38;5;241m.\u001b[39mcv_results_\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1749\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1748\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1749\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n","File \u001b[0;32m~/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: \nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'M'\n\n--------------------------------------------------------------------------------\n400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 173, in fit\n    X, y = self._validate_data(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 856, in check_array\n    array = np.asarray(array, order=order, dtype=dtype)\n  File \"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/pandas/core/generic.py\", line 2064, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: 'F'\n"]}},"pos":37,"start":1659369133303,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4bb01a","input":"heart_dfs = heart_df.copy()\ntarget = heart_dfs[\"HeartDisease\"]\ninput_columns = heart_dfs.loc[:, heart_dfs.columns != \"HeartDisease\"]\ny = heart_df[\"HeartDisease\"]\nparam_grid = {'n_neighbors': range(1, 400)}\n\nx = KNN()\ngrid_x = GridSearchCV(x, param_grid)\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2,stratify =y, random_state=42)\n\ngrid_x.fit(x_train, y_train)\nprint(grid_x.best_params_)","pos":14,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"5679c3","input":"y_pred_proba = classifier.predict_proba(x_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"heart dataframe, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n\"\"\"fpr = dict()\ntpr = dict()\nroc_auc = dict()\n\ny = label_binarize(y, classes=[0, 1, 2,])\nn_classes = y.shape[1]\n\n\nfor i in y_test:\n    i = int(i)\ny_test = list(y_test)\nfor i in y_pred:\n    i = int(i)\ny_pred = list(y_pred)\nprint(type(y_test))\nfor i in y_pred:\n    for x in y_test:\n        if i == -1 <= x:\n            print(i)\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[0:i], y_pred[0:i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\nplt.figure()\nlw = 2\nplt.plot(\n    fpr[2],\n    tpr[2],\n    color=\"darkorange\",\n    lw=lw,\n    label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n)\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver operating characteristic example\")\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n#This plots the tradeoff of positive rate to false positive rate(roc curve)\"\"\"\n\"\"\"fitted_y = np.array(y_pred)\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(heart_df.loc[:, heart_df.columns != \"HeartDisease\"],heart_df['HeartDisease'],c='red', marker='o', alpha=0.5)\nax.plot_surface(x_test,y_test,y_pred.reshape(x_test.shape), color='b', alpha=0.3)\nax.set_xlabel('Price')\nax.set_ylabel('AdSpends')\nax.set_zlabel('Sales')\nplt.show()\"\"\"","pos":24,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"605396","input":"\"\"\"#y_hat = KNN_model.predict(x_test)\nmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#00AAFF'])\ncmap_bold = ListedColormap(['#FF0000', '#00FF00', '#00AAFF'])\n\nclf = neighbors.KNeighborsClassifier(n_neighbors = 23, weights='distance')\nclf.fit(x_train, y_train)\n\nx_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\ny_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\"\"\"","pos":17,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"7a3683","input":"heart_dfs = heart_df.copy()\ntarget = heart_dfs[\"HeartDisease\"]\ninput_columns = heart_dfs.loc[:, heart_dfs.columns != \"HeartDisease\"]\n#sc = StandardScaler()\n#x_train = sc.fit_transform(x_train)\n#x_test = sc.transform(x_test)\n\n\n\n\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2,stratify =target, random_state=42)\nKNN_OLD_MODEL = KNN()\nKNN_model = KNN(n_neighbors = 23)\nKNN_model.fit(x_train,y_train)\n\ny_hat = KNN_model.predict(x_test)\n\ntotal_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)\n\n\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_hat)\nprec = precision_score(y_test, y_hat)\nrecall = recall_score(y_test, y_hat)\nf1 = f1_score(y_test, y_hat)\nscores['KNN_ADJUSTED'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['KNN_ADJUSTED'])","pos":15,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ae328d","input":"","pos":0,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b8439d","input":"","pos":7,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ee5f57","input":"","pos":39,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f72a8a","input":"#x is everything but heart disease\nx = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\n#y is heart disease\ny = heart_df['HeartDisease']\n# splits dataset; 80 percent train: 20 percent test\nx_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)\n#scales down the x values\nst_x= StandardScaler()\nx_train= st_x.fit_transform(x_train)\nx_test= st_x.transform(x_test)\nclassifier = LogisticRegression(random_state=42)\n#Fits dataset\nclassifier.fit(x_train, y_train)\n#gets predicted values\ny_pred= classifier.predict(x_test)\n#compares predictions to actual values\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n\n\"\"\"total_squared_error = (np.sum((y_test - y_pred)**2))\nmean_squared_error = total_squared_error/len(y_test)\nprint(mean_squared_error)\"\"\"\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\nscores['LOGISTICREGRESSION'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['LOGISTICREGRESSION'])\n\n","pos":22,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":25,"id":"5715dd","input":"scores = {}\nscores['metrics'] = {'accuracy': 'accuracy', 'precision':'precision', 'recall':'recall', 'f1_score':'f1_score'}","pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":259,"id":"1f6bde","input":"#predicting results\n#y_hat = my_SVC_model.predict(x_test)","pos":32,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":26,"id":"00f5ec","input":"target = heart_df[\"HeartDisease\"]\ninput_columns = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.3)","pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":260,"id":"be3779","input":"#y_hat","output":{"0":{"data":{"text/plain":"array([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n       1, 1, 1, 1, 0, 0, 0, 1])"},"exec_count":260,"output_type":"execute_result"}},"pos":33,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":261,"id":"a2715d","input":"#np.array(y_test)","output":{"0":{"data":{"text/plain":"array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n       1, 1, 1, 1, 0, 1, 0, 1])"},"exec_count":261,"output_type":"execute_result"}},"pos":34,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":265,"id":"e8d731","input":"#MSE\n#total_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\n#mean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \n#print(mean_squared_error)","output":{"0":{"name":"stdout","output_type":"stream","text":"0.14673913043478262\n"}},"pos":35,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":266,"id":"26cd3d","input":"#Confusion Matrix\n#sns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\n#acc = accuracy_score(y_test, y_hat)\n#fone_score = f1_score(y_test, y_hat)\n#rec = recall_score(y_test, y_hat)\n#prec = precision_score(y_test, y_hat)\n\n#accuracy, f1 score, recall, precision\n#print(\"Accuracy: \" , acc , \"f1 Score: \" , fone_score, \"Recall: \" , rec, \"Precision: \" , prec)","output":{"0":{"name":"stdout","output_type":"stream","text":"Accuracy:  0.8532608695652174 f1 Score:  0.8601036269430051 Recall:  0.8924731182795699 Precision:  0.83\n"},"1":{"data":{"image/png":"f07bf6d88f4176f85f4ff20d1d4eacf8fec22207","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":266,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":36,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"eb41fc","input":"heart_dfs = heart_df.copy()\ntarget = heart_dfs[\"HeartDisease\"]\ninput_columns = heart_dfs.loc[:, heart_dfs.columns != \"HeartDisease\"]\ny = heart_df[\"HeartDisease\"]\nparam_grid = {'var_smoothing':range(0,200)}\nx = GaussianNB()\ngrid_x = GridSearchCV(x, param_grid)\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2,stratify =y, random_state=42)\n\ngrid_x.fit(x_train, y_train)\nprint(grid_x.best_params_)","output":{"0":{"ename":"NameError","evalue":"name 'heart_df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m heart_dfs \u001b[38;5;241m=\u001b[39m \u001b[43mheart_df\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m target \u001b[38;5;241m=\u001b[39m heart_dfs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeartDisease\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m input_columns \u001b[38;5;241m=\u001b[39m heart_dfs\u001b[38;5;241m.\u001b[39mloc[:, heart_dfs\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeartDisease\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'heart_df' is not defined"]}},"pos":25,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":40,"id":"ef2113","input":"#ADABOOST\n# parameters = {'n_estimators':[50, 100, 125, 150], 'learning_rate': [0.01, 0.1, 0.3, 0.5]}\n# scoring = ['precision', 'accuracy', 'recall', 'f1']\n\n\n# for score in scoring:\n#     abc = AdaBoostClassifier()\n#     grid_abc = GridSearchCV(abc, parameters, scoring=score)\n#     grid_abc.fit(x_train, y_train)\n\n\n#     print(\"best params for %s: \" % score)\n#     print(grid_abc.best_params_)\n\n#     means = grid_abc.cv_results_[\"mean_test_score\"]\n\n#     print(\"mean scores\")\n#     for mean, params in zip(means, grid_abc.cv_results_[\"params\"]):\n#         print(\"%0.5f for %r\" % (mean, params))\n\nabc = AdaBoostClassifier(n_estimators=100, learning_rate=0.1)\nabc.fit(x_train, y_train)\n\ny_predictions = abc.predict(x_test)\n\ntotal_squared_error = (np.sum((y_test - y_predictions)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \n#print(mean_squared_error)\nsns.heatmap(confusion_matrix(y_test, y_predictions), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_predictions)\nprec = precision_score(y_test, y_predictions, average='micro')\nrecall = recall_score(y_test, y_predictions, average='micro')\nf1 = f1_score(y_test, y_predictions, average='micro')\nscores['Adaboost'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['Adaboost'])\n\n","output":{"0":{"name":"stdout","output_type":"stream","text":"0.11956521739130435\n{'accuracy': 0.8804347826086957, 'precision': 0.8804347826086957, 'recall': 0.8804347826086957, 'f1_score': 0.8804347826086957}\n"},"1":{"data":{"image/png":"dc1625ddce5e820f486556eef8678781fb9c063d","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":40,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":12,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":42,"id":"c6494e","input":"x_test.shape","output":{"0":{"data":{"text/plain":"(184, 11)"},"exec_count":42,"output_type":"execute_result"}},"pos":10,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":47,"id":"b814ee","input":"#from sklearn.svm import SVC\n\n#changing the kernel\n#my_SVC_model = SVC(kernel = 'rbf')\n\n#fitting the model\n#my_SVC_model.fit(x_train, y_train)","pos":31,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":56,"id":"c1e1c5","input":"","output":{"0":{"data":{"text/plain":"184"},"exec_count":56,"output_type":"execute_result"}},"pos":29,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":64,"id":"6c1a32","input":"(89)/(89+12)\n(65)/(65+18)","output":{"0":{"data":{"text/plain":"0.7831325301204819"},"exec_count":64,"output_type":"execute_result"}},"pos":28,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":70,"id":"ded656","input":"#print(y_hat)\nprint(np.array(y_test))\n\n\"\"\"total_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)\"\"\"\n\"\"\"sns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_hat)\nprec = precision_score(y_test, y_hat, average='micro')\nrecall = recall_score(y_test, y_hat, average='micro')\nf1 = f1_score(y_test, y_hat, average='micro')\nscores['KNN'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['KNN'])\"\"\"","output":{"0":{"name":"stdout","output_type":"stream","text":"[1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1\n 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1\n 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1\n 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0\n 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1]\n"},"1":{"data":{"text/plain":"\"sns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\\nacc = accuracy_score(y_test, y_hat)\\nprec = precision_score(y_test, y_hat, average='micro')\\nrecall = recall_score(y_test, y_hat, average='micro')\\nf1 = f1_score(y_test, y_hat, average='micro')\\nscores['KNN'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\\nprint(scores['KNN'])\""},"exec_count":70,"output_type":"execute_result"}},"pos":18,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":71,"id":"e7eb4b","input":"mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(1000, 35), alpha=0.05, max_iter=200, random_state = 1, activation='relu', learning_rate='adaptive')\nmlp.fit(x_train, y_train)\ny_hat = mlp.predict(x_test)\nprint(y_hat)\nprint(np.array(y_test))\ntotal_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\nacc = accuracy_score(y_test, y_hat)\nprec = precision_score(y_test, y_hat, average='micro')\nrecall = recall_score(y_test, y_hat, average='micro')\nf1 = f1_score(y_test, y_hat, average='micro')\nscores['mlp'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['mlp'])","output":{"0":{"name":"stdout","output_type":"stream","text":"[1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1\n 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1\n 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1\n 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1\n 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1]\n[1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1\n 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1\n 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1\n 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0\n 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1]\n0.16304347826086957\n{'accuracy': 0.8369565217391305, 'precision': 0.8369565217391305, 'recall': 0.8369565217391305, 'f1_score': 0.8369565217391305}\n"},"1":{"name":"stderr","output_type":"stream","text":"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"},"2":{"data":{"image/png":"cae88457aa26460aecf0200d826df5436b19315f","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":71,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":19,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":72,"id":"d8b80d","input":"# Please save scores like the example below\nscores['knn'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}","pos":20,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":82,"id":"9f2cce","input":"# define x as all columns but heart disease\n\nX = heart_df.loc[:, heart_df.columns != \"HeartDisease\"]\nX = (X - np.min(X)) / (np.max(X) - np.min(X))\n#define y as heart_disease\ny = heart_df['HeartDisease']\n#split data set 80 percent train: 20 percent test\n\n\nn_iter = 1000\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n#scales down x_values\nst_x= StandardScaler()\nx_train= st_x.fit_transform(X_train)\nx_test= st_x.transform(X_test)\nthresholder = VarianceThreshold(threshold=.5)\n\nx_train = thresholder.fit_transform(x_train)\nx_test = thresholder.fit_transform(x_test)\n#create object model\ngnb = GaussianNB(priors=None, var_smoothing=1e-06)\n#fit object model\ngnb.fit(x_train, y_train)\nGaussianNB(priors=None, var_smoothing= 1)\ny_pred = gnb.predict(x_test)\n#print(\"Naive Bayes score: \",gnb.score(X_test, y_test))#\n#print(\"Number of mislabeled points out of a total %d points : %d\"\n\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\nscores['NAIVEBAYES'] = {'accuracy': acc, 'precision':prec, 'recall':recall, 'f1_score':f1}\nprint(scores['NAIVEBAYES'])\nprint(\"Naive Bayes score: \",gnb.score(x_test, y_test))\n","output":{"0":{"name":"stdout","output_type":"stream","text":"{'accuracy': 0.8858695652173914, 'precision': 0.8785046728971962, 'recall': 0.9215686274509803, 'f1_score': 0.8995215311004785}\nNaive Bayes score:  0.8858695652173914\n"},"1":{"name":"stderr","output_type":"stream","text":"/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n  return reduction(axis=axis, out=out, **passkwargs)\n/projects/d5a3aa23-997d-4ffc-977a-1dc20c583e62/miniconda3/envs/ds_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n  return reduction(axis=axis, out=out, **passkwargs)\n"},"2":{"data":{"image/png":"deb0b7fb4c9c360871651d14c389926a4b8624e5","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":82,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":26,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1de317","input":"grid search cv","pos":11,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3d6727","input":"Support Vector Classification Model uses two groups of data to categorize new data.  It does this by plotting the data onto a graph, and then using a hyperplane to split the data according to the group that the data belongs to. The hyper\\-parameters  that could be fine tuned are the kernel, the C value, the Gamma value, and the Degree. I decided to use a RandomizedSearchCV to \n\n","pos":38,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"594fc7","input":"The model is a logistic regression and it works by predicting whether someone has heart disease or if they do not. It classifies them into one of these two groups . We changed some parameters such as the weight, training and testing data. I think it performed well in predicting if someone has heart disease and classifying them into two groups.\n\n","pos":21,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c0d2b5","input":"","pos":23,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c6a4b2","input":"Adaboost is an example of ensemble learning, where several basic algorithms are combined to make one more optimized algorithm. For example, with a decision tree, instead of hoping 1 decision tree can correctly guess a result, ensemble learning will take multiple decision trees and combine them together to create a stronger algorithm.\n\nAdaboost is also a sequential learning version of ensemble learning, where every model is made in order, and the newest model learns from the previous model's failures. It does this by \"boosting\", or reducing the error through methods such as increasing the weights of data that was mislabelled.\n\nHowever, Adaboost is extremely sensitive to noisy data and outliers, which is why it is highly recommended to remove outliers from data with Adaboost.\n\nHere, Adaboost was used on our heart disease dataset, with a mean squared error of 0.12 on our testing data, and an overall accuracy score of 0.880 and a precision score of 0.880. There were 13 false positives and 9 false negatives, which were\n","pos":13,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d38595","input":"**NOTE:** PLEASE save the scores to the score dictionary \n\nModels to try out:\n\n- Decision Tree \\(Emma\\)\n- Random Forest \\(Emma\\)\n- Adaboost\n- SVC\n- \n- NEURAL NETWORKS  Thomas\n- KNN\n- Logistic Regression \\(kenju\\)\n- Naive bayes\n- \n- \n- Naive Bayes \\(Rhone\\)\n- Adaboost \\(Jeffrey\\)\n- Support vector classifier \\(halli\\)\n- \n- Stochastic Gradient Descent Classifier \\(SGDClassifier\\)\n  - https://scikit\\-learn.org/stable/modules/generated/sklearn.linear\\_model.SGDClassifier.html\n- Support vector classifier \n- KNN \\(Rhone\\)\n- \n- \n\n<u>**AlSO TRY OPTIMIZING THEM**</u>\n\nGrid Search CV\n\nEvaluation metrics:\n\n- F1 score\n- Accuracy\n- Recall\n- Precision\n- Confusion matrix\n\n","pos":6,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e37112","input":"Gaussian Naive Bayes is for binary classification and assumes that all continuous data has normal distribution, and that all features are independent and equal from each other. The Naive Bayes finds the probability of the predicted outcome\\(y variable\\) given the x values and then classifies the point based on whether one of the classifications had a higher probability than the other classification. In order to optimize the function, I stratified the data, which raised the accuracy score from 0.83 to 0.885 while also scaling the data though that did not cause a change in the accuracy score or any of the other measures. The results ending up giving a accuracy score of 0.885, a precision score of 0.878, a recall score of 0.921, and an f1 score of 0.899. This resulted in 8 false negatives and 13 false positives out of 184 points in what I believe can be described as an accurate model.\n\n","pos":27,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f8ef79","input":"The KNN nearest neighbors function looks for the k nearest neighbors of a point and their classification and then classifies the point based on the state of the nearest neighbors. Using GridSearchCV, I tried to optimize the value of the k nearest neighbors in a range from 1 to 400 and it was found that 23 was the most optimal number. It ended up giving a success rate of roughly 72.8 percent with 25 false positives and 25 false negative, 57 correct positives, and 77 correct negatives, a recall rate of 75.5 percent a precision rate of 75.5 percent, and an f1\\_score of 75.5 percent. These numbers would be described as a moderately \\-to good accurate model.\n\n","pos":16,"state":"done","type":"cell"}
{"id":0,"time":1659369051314,"type":"user"}
{"last_load":1659362328185,"type":"file"}